# ä¼ä¸šçº§ Agent å¼€å‘å®æˆ˜(ä¸€) LangGraph å¿«é€Ÿå…¥é—¨

> åœ¨å½“ä»Š AI å¿«é€Ÿå‘å±•çš„æ—¶ä»£ï¼Œå•çº¯çš„é—®ç­”å¼ AI å·²ç»æ— æ³•æ»¡è¶³å¤æ‚ä¸šåŠ¡éœ€æ±‚ã€‚ä¼ä¸šéœ€è¦çš„æ˜¯èƒ½å¤Ÿè‡ªä¸»æ€è€ƒã€è§„åˆ’å’Œæ‰§è¡Œçš„æ™ºèƒ½ä½“Agentã€‚LangGraph ä½œä¸º LangChain ç”Ÿæ€ä¸­çš„å›¾å½¢å·¥ä½œæµæ¡†æ¶ï¼Œä¸ºæˆ‘ä»¬æ„å»ºè¿™æ ·çš„æ™ºèƒ½ä½“æä¾›äº†å¼ºå¤§çš„åŸºç¡€è®¾æ–½ã€‚

## å‰è¨€

è¿˜è®°å¾—ç¬¬ä¸€æ¬¡æ¥è§¦ä¼ ç»Ÿçš„AIèŠå¤©æœºå™¨äººæ—¶ï¼Œé‚£ç§"ä¸€é—®ä¸€ç­”"çš„äº¤äº’æ–¹å¼æ€»è®©äººæ„Ÿè§‰ç¼ºå°‘äº›ä»€ä¹ˆã€‚å®ƒä»¬å°±åƒæ˜¯è®­ç»ƒæœ‰ç´ çš„å®¢æœï¼Œèƒ½å›ç­”é¢„è®¾çš„é—®é¢˜ï¼Œä½†é¢å¯¹å¤æ‚çš„ä¸šåŠ¡åœºæ™¯å´æ˜¾å¾—åŠ›ä¸ä»å¿ƒã€‚

çœŸæ­£çš„æ™ºèƒ½ä½“åº”è¯¥åƒä¸€ä¸ªç»éªŒä¸°å¯Œçš„åŠ©æ‰‹ï¼Œèƒ½å¤Ÿç†è§£å¤æ‚éœ€æ±‚ã€åˆ¶å®šæ‰§è¡Œè®¡åˆ’ã€è°ƒç”¨å„ç§å·¥å…·å®Œæˆä»»åŠ¡ï¼Œç”šè‡³åœ¨å¿…è¦æ—¶ä¸»åŠ¨å¯»æ±‚äººå·¥ç¡®è®¤ã€‚è¿™å°±æ˜¯LangGraphè¦è§£å†³çš„æ ¸å¿ƒé—®é¢˜â€”â€”è®©AIä»ç®€å•çš„"åº”ç­”è€…"å‡çº§ä¸ºå¤æ‚çš„"æ‰§è¡Œè€…"ã€‚



[ä¼ä¸šçº§ Agent å¼€å‘å®æˆ˜(ä¸€) LangGraph å¿«é€Ÿå…¥é—¨]()

[ä¼ä¸šçº§ Agent å¼€å‘å®æˆ˜(äºŒ) å®æˆ˜MCPServer]()

[ä¼ä¸šçº§ Agent å¼€å‘å®æˆ˜(ä¸‰) æ™ºèƒ½è¿ç»´ Agent å¼€å‘]()



è¯¥ç³»åˆ—æ–‡ç« æœ€ç»ˆä¼šå®ç°ä¸€ä¸ªæ™ºèƒ½è¿ç»´åˆ†æ Agent ï¼Œæ•ˆæœå¦‚ä¸‹:

![](http://devyk.top/2022/202508201942430.gif)





## ä¸€ã€ä»€ä¹ˆæ˜¯LangGraphï¼Ÿæ ¸å¿ƒæ¦‚å¿µè§£æ

### 1.1 ä»çº¿æ€§å¯¹è¯åˆ°å›¾å½¢å·¥ä½œæµ

ä¼ ç»Ÿçš„ AI åº”ç”¨å¾€å¾€æ˜¯çº¿æ€§çš„ï¼šç”¨æˆ·è¾“å…¥ â†’ AIå¤„ç† â†’ è¿”å›ç»“æœã€‚ä½†ç°å®ä¸–ç•Œçš„é—®é¢˜å¾€å¾€éœ€è¦å¤šæ­¥éª¤ã€æœ‰æ¡ä»¶çš„å†³ç­–è¿‡ç¨‹ã€‚

LangGraphå°†è¿™ä¸ªè¿‡ç¨‹æŠ½è±¡ä¸ºä¸€ä¸ª**æœ‰å‘å›¾**ï¼Œå…¶ä¸­ï¼š

- **èŠ‚ç‚¹(Nodes)** ä»£è¡¨å…·ä½“çš„å¤„ç†é€»è¾‘
- **è¾¹(Edges)** å®šä¹‰æ•°æ®æµå‘å’Œæ‰§è¡Œé¡ºåº  
- **çŠ¶æ€(State)** åœ¨èŠ‚ç‚¹é—´ä¼ é€’çŠ¶æ€æ•°æ®å’Œæ›´æ–°æ•°æ®

é€šè¿‡ç»„åˆ Nodes å’Œ Edges ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºå¤æ‚çš„å¾ªç¯å·¥ä½œæµï¼Œä½¿çŠ¶æ€éšæ—¶é—´æ¨ç§»è€Œæ¼”å˜ã€‚ç„¶è€Œï¼ŒçœŸæ­£çš„å¼ºå¤§ä¹‹å¤„åœ¨äº LangGraph çš„çŠ¶æ€ç®¡ç†æ–¹å¼ã€‚éœ€è¦å¼ºè°ƒçš„æ˜¯ï¼šNodes å’Œ Edges ä»…ä»…æ˜¯å‡½æ•°è€Œå·²ï¼Œå®ƒä»¬å¯ä»¥åŒ…å« LLM ä»£ç ï¼Œä¹Ÿå¯ä»¥åªæ˜¯ä¸€äº›æ™®é€šçš„ä»£ç ã€‚



> ç®€è€Œè¨€ä¹‹ï¼šèŠ‚ç‚¹è´Ÿè´£å·¥ä½œï¼Œè¾¹è´Ÿè´£å‘Šè¯‰ä¸‹ä¸€æ­¥åšä»€ä¹ˆï¼Œ çŠ¶æ€å°±æ˜¯å…±äº«çš„æ•°æ®ã€‚



è¿™ç§è®¾è®¡å¯ä»¥è®©æˆ‘ä»¬èƒ½å¤Ÿæ„å»ºçœŸæ­£çš„"æ€è€ƒé“¾"ï¼š

```python
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict

class AgentState(TypedDict):
    task: str
    steps_completed: list
    current_step: str
    result: str

# åˆ›å»ºçŠ¶æ€å›¾
workflow = StateGraph(AgentState)
....
workflow.compile(...)
```

### 1.2 çŠ¶æ€ç®¡ç†ï¼šæ™ºèƒ½ä½“çš„"è®°å¿†ç³»ç»Ÿ"

çŠ¶æ€ (State) æ˜¯ LangGraph çš„æ ¸å¿ƒæ¦‚å¿µä¹‹ä¸€ã€‚å®ƒä¸ä»…ä»…æ˜¯æ•°æ®çš„è½½ä½“ï¼Œæ›´åƒæ˜¯æ™ºèƒ½ä½“çš„"å·¥ä½œè®°å¿†"ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œä¸€ä¸ªä¼˜ç§€çš„é¡¹ç›®ç»ç†åœ¨æ¨è¿›é¡¹ç›®æ—¶ï¼Œè„‘ä¸­ä¼šä¿æŒå¯¹å½“å‰è¿›åº¦ã€å¾…åŠäº‹é¡¹ã€é‡åˆ°é—®é¢˜çš„æ¸…æ™°è®¤çŸ¥ã€‚

```python
class ProjectState(TypedDict):
    requirements: str      # é¡¹ç›®éœ€æ±‚
    current_phase: str    # å½“å‰é˜¶æ®µ
    completed_tasks: list # å·²å®Œæˆä»»åŠ¡
    issues: list         # é‡åˆ°çš„é—®é¢˜
    team_feedback: str   # å›¢é˜Ÿåé¦ˆ
```

çŠ¶æ€åœ¨èŠ‚ç‚¹é—´æµè½¬æ—¶ä¼šè¢«æ›´æ–°å’Œä¸°å¯Œï¼Œå½¢æˆäº†æ™ºèƒ½ä½“çš„"æ€è€ƒè½¨è¿¹"ã€‚

## äºŒã€å›¾å½¢APIï¼šæ„å»ºæ™ºèƒ½ä½“çš„è“å›¾

### 2.1 èŠ‚ç‚¹è®¾è®¡ï¼šåˆ†è€Œæ²»ä¹‹çš„æ™ºæ…§

æ¯ä¸ªèŠ‚ç‚¹éƒ½ä»£è¡¨ä¸€ä¸ªå…·ä½“çš„åŠŸèƒ½æ¨¡å—ã€‚å¥½çš„èŠ‚ç‚¹è®¾è®¡éµå¾ªå•ä¸€èŒè´£åŸåˆ™ï¼Œè®©å¤æ‚çš„ä¸šåŠ¡é€»è¾‘å˜å¾—æ¸…æ™°å¯ç»´æŠ¤ã€‚

```python
def analyze_requirements(state: ProjectState) -> ProjectState:
    """éœ€æ±‚åˆ†æèŠ‚ç‚¹"""
    requirements = state["requirements"]
    
    # ä½¿ç”¨LLMåˆ†æéœ€æ±‚
    llm = get_llm()
    analysis = llm.invoke(f"åˆ†æé¡¹ç›®éœ€æ±‚: {requirements}")
    
    return {
        **state,
        "current_phase": "éœ€æ±‚åˆ†æ",
        "completed_tasks": state["completed_tasks"] + ["éœ€æ±‚åˆ†æå®Œæˆ"]
    }

def create_plan(state: ProjectState) -> ProjectState:
    """åˆ¶å®šè®¡åˆ’èŠ‚ç‚¹"""
    # åŸºäºåˆ†æç»“æœåˆ¶å®šè¯¦ç»†è®¡åˆ’
    return {
        **state,
        "current_phase": "è®¡åˆ’åˆ¶å®š"
    }
```

### 2.2 è¾¹çš„è‰ºæœ¯ï¼šæ§åˆ¶æ‰§è¡Œæµç¨‹

LangGraphæä¾›äº†çµæ´»çš„è¾¹å®šä¹‰æ–¹å¼ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿå®ç°å¤æ‚çš„æ¡ä»¶é€»è¾‘ï¼š

```python
def should_seek_approval(state: ProjectState) -> str:
    """æ¡ä»¶è¾¹ï¼šå†³å®šæ˜¯å¦éœ€è¦å®¡æ‰¹"""
    if "é«˜é£é™©" in state.get("issues", []):
        return "human_review"
    else:
        return "auto_proceed"

# æ·»åŠ æ¡ä»¶è¾¹
workflow.add_conditional_edges(
    "analyze_requirements",
    should_seek_approval,
    {
        "human_review": "wait_for_approval", 
        "auto_proceed": "create_plan"
    }
)
```

è¿™ç§è®¾è®¡è®©æ™ºèƒ½ä½“èƒ½å¤Ÿæ ¹æ®å®é™…æƒ…å†µåŠ¨æ€è°ƒæ•´æ‰§è¡Œè·¯å¾„ï¼Œå°±åƒä¸€ä¸ªæœ‰ç»éªŒçš„ä¸“å®¶ä¼šæ ¹æ®å…·ä½“æƒ…å†µçµæ´»åº”å¯¹ã€‚

### 2.3 ç¼–è¯‘ä¸æ‰§è¡Œï¼šè®©å›¾"æ´»"èµ·æ¥

å®šä¹‰å¥½å›¾ç»“æ„åï¼Œéœ€è¦ç¼–è¯‘æˆå¯æ‰§è¡Œçš„åº”ç”¨ï¼š

```python
# æ„å»ºå®Œæ•´çš„å·¥ä½œæµ
workflow.add_node("analyze", analyze_requirements)
workflow.add_node("plan", create_plan)
workflow.set_entry_point("analyze")
workflow.add_edge("plan", END)

# ç¼–è¯‘æˆå¯æ‰§è¡Œåº”ç”¨
app = workflow.compile()

# æ‰§è¡Œå·¥ä½œæµ
result = app.invoke({
    "requirements": "å¼€å‘ä¸€ä¸ªå®¢æˆ·å…³ç³»ç®¡ç†ç³»ç»Ÿ",
    "steps_completed": [],
    "current_step": "",
    "result": ""
})
```

## ä¸‰ã€æµå¼ä¼ è¾“ï¼šå®æ—¶æ„ŸçŸ¥æ™ºèƒ½ä½“æ€è€ƒ

### 3.1 ä¸ºä»€ä¹ˆéœ€è¦æµå¼ä¼ è¾“ï¼Ÿ

æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ å§”æ‰˜ä¸€ä¸ªåŠ©æ‰‹å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œä½ è‚¯å®šå¸Œæœ›èƒ½å¤Ÿå®æ—¶äº†è§£è¿›å±•ï¼Œè€Œä¸æ˜¯è‹¦è‹¦ç­‰å¾…æœ€ç»ˆç»“æœã€‚æµå¼ä¼ è¾“æ­£æ˜¯ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ã€‚

LangGraph æä¾›äº†å¤šç§æµå¼ä¼ è¾“æ¨¡å¼ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿä»ä¸åŒè§’åº¦è§‚å¯Ÿæ™ºèƒ½ä½“çš„æ‰§è¡Œè¿‡ç¨‹ã€‚

### 3.2 æ”¯æŒçš„æµå¼ä¼ è¾“æ¨¡å¼

LangGraph æˆªæ­¢ç›®å‰æ”¯æŒä»¥ä¸‹å‡ ç§æµå¼ä¼ è¾“æ¨¡å¼ï¼š

| æ¨¡å¼       | æè¿°                           | é€‚ç”¨åœºæ™¯                           |
| ---------- | ------------------------------ | ---------------------------------- |
| `values`   | æµå¼ä¼ è¾“æ¯ä¸ªæ­¥éª¤åçš„å®Œæ•´çŠ¶æ€   | éœ€è¦æŸ¥çœ‹å®Œæ•´çŠ¶æ€å˜åŒ–æ—¶             |
| `updates`  | æµå¼ä¼ è¾“æ¯ä¸ªæ­¥éª¤çš„çŠ¶æ€æ›´æ–°     | éœ€è¦è¿½è¸ªçŠ¶æ€å˜åŒ–å¢é‡æ—¶             |
| `messages` | æµå¼ä¼ è¾“LLMç”Ÿæˆçš„tokenå’Œå…ƒæ•°æ® | éœ€è¦å®æ—¶æ˜¾ç¤ºAIç”Ÿæˆå†…å®¹æ—¶           |
| `custom`   | æµå¼ä¼ è¾“è‡ªå®šä¹‰æ•°æ®             | éœ€è¦ä¼ è¾“å·¥å…·æ‰§è¡Œè¿›åº¦ç­‰è‡ªå®šä¹‰ä¿¡æ¯æ—¶ |
| `debug`    | æµå¼ä¼ è¾“å°½å¯èƒ½å¤šçš„è°ƒè¯•ä¿¡æ¯     | è°ƒè¯•å’Œæ•…éšœæ’é™¤æ—¶                   |

### 3.3 valuesæ¨¡å¼ï¼šè§‚å¯Ÿå®Œæ•´çŠ¶æ€

```python
# æµå¼è·å–å®Œæ•´çŠ¶æ€
for chunk in app.stream(initial_state, stream_mode="values"):
    print("ğŸ“Š å½“å‰å®Œæ•´çŠ¶æ€:", chunk)
```

è¿™ç§æ¨¡å¼è®©ä½ èƒ½å¤Ÿçœ‹åˆ°æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåçš„å®Œæ•´çŠ¶æ€ï¼Œå°±åƒæ˜¯ç»™æ™ºèƒ½ä½“æ‹å¿«ç…§ã€‚

### 3.4 updatesæ¨¡å¼ï¼šè¿½è¸ªçŠ¶æ€å˜åŒ–

```python
# æµå¼è·å–çŠ¶æ€æ›´æ–°
for chunk in app.stream(initial_state, stream_mode="updates"):
    node_name = list(chunk.keys())[0]
    update_data = chunk[node_name]
    print(f"ğŸ”„ èŠ‚ç‚¹ {node_name} æ›´æ–°: {update_data}")
```

è¿™ç§æ¨¡å¼åªæ˜¾ç¤ºçŠ¶æ€çš„å˜åŒ–éƒ¨åˆ†ï¼Œæ›´åŠ é«˜æ•ˆï¼Œé€‚åˆè¿½è¸ªå…·ä½“çš„æ›´æ–°ã€‚

### 3.5 messagesæ¨¡å¼ï¼šå®æ—¶æ˜¾ç¤ºAIç”Ÿæˆå†…å®¹

```python
# æµå¼è·å–LLM token
for message_chunk, metadata in app.stream(
    initial_state, 
    stream_mode="messages"
):
    if message_chunk.content:
        print(message_chunk.content, end="", flush=True)
    print(f"\nå…ƒæ•°æ®: {metadata}")
```

è¿™ç§æ¨¡å¼è®©ç”¨æˆ·èƒ½å¤Ÿçœ‹åˆ°AI"æ€è€ƒ"çš„è¿‡ç¨‹ï¼Œtokenä¸€ä¸ªä¸ªåœ°ç”Ÿæˆï¼Œå°±åƒæˆ‘ä»¬åœ¨æ‰“å­—ä¸€æ ·ï¼Œè¿™ç§äº¤äº’æ–¹å¼ç›®å‰æœ€æ¨èä½¿ç”¨ï¼Œäº¤äº’æ•ˆæœæœ€å¥½ã€‚

### 3.6 customæ¨¡å¼ï¼šä¼ è¾“è‡ªå®šä¹‰æ•°æ®

```python
from langgraph.config import get_stream_writer

def progress_tool(query: str) -> str:
    """ä¸€ä¸ªå±•ç¤ºè¿›åº¦çš„å·¥å…·"""
    writer = get_stream_writer()
    
    for i in range(1, 6):
        writer(f"å¤„ç†è¿›åº¦: {i*20}%")
        time.sleep(1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
    
    return "å¤„ç†å®Œæˆ"

# æµå¼è·å–è‡ªå®šä¹‰æ•°æ®
for chunk in app.stream(initial_state, stream_mode="custom"):
    print(f"ğŸ“ˆ è¿›åº¦æ›´æ–°: {chunk}")
```

### 3.7 å¤šæ¨¡å¼ç»„åˆï¼šå…¨æ–¹ä½ç›‘æ§

```python
# åŒæ—¶ä½¿ç”¨å¤šç§æ¨¡å¼
for mode, chunk in app.stream(
    initial_state, 
    stream_mode=["updates", "messages", "custom"]
):
    if mode == "updates":
        print(f"ğŸ”„ çŠ¶æ€æ›´æ–°: {chunk}")
    elif mode == "messages":
        print(f"ğŸ’¬ æ¶ˆæ¯: {chunk[0].content}")
    elif mode == "custom":
        print(f"ğŸ“ˆ è‡ªå®šä¹‰æ•°æ®: {chunk}")
```



## å››ã€è®°å¿†ç³»ç»Ÿï¼šæ„å»ºæœ‰å†å²çš„æ™ºèƒ½ä½“

è®°å¿†æ˜¯æ™ºèƒ½ä½“åŒºåˆ«äºç®€å•èŠå¤©æœºå™¨äººçš„å…³é”®ç‰¹å¾ã€‚LangGraph æä¾›äº†å®Œæ•´çš„è®°å¿†ç³»ç»Ÿï¼ŒåŒ…æ‹¬çŸ­æœŸè®°å¿†å’Œé•¿æœŸè®°å¿†ä¸¤ç§ç±»å‹ï¼Œå¹¶æ”¯æŒå¤šç§æŒä¹…åŒ–å­˜å‚¨æ–¹æ¡ˆã€‚

### 4.1 çŸ­æœŸè®°å¿†ï¼šçº¿ç¨‹çº§çš„å¯¹è¯ä¸Šä¸‹æ–‡

çŸ­æœŸè®°å¿†åœ¨LangGraphä¸­é€šè¿‡çº¿ç¨‹çº§ï¼ˆthread-scopedï¼‰çŠ¶æ€å®ç°ï¼Œèƒ½å¤Ÿåœ¨å•ä¸ªå¯¹è¯çº¿ç¨‹ä¸­ä¿æŒä¸Šä¸‹æ–‡ã€‚è¿™å°±åƒäººç±»çš„å·¥ä½œè®°å¿†ï¼Œèƒ½å¤Ÿè®°ä½å½“å‰å¯¹è¯çš„å†…å®¹å’ŒèƒŒæ™¯ã€‚

#### 4.1.1 æŒä¹…åŒ–å­˜å‚¨é…ç½®

çº¿ä¸Šä¼ä¸šçº§çš„åº”ç”¨éœ€è¦çœŸæ­£çš„æŒä¹…åŒ–å­˜å‚¨ã€‚LangGraphæ”¯æŒå¤šç§å­˜å‚¨åç«¯ï¼š

```python
from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.checkpoint.postgres import PostgresSaver
from langgraph.checkpoint.memory import InMemorySaver, MemorySaver
from langgraph.store.sqlite import SqliteStore
from langgraph.store.postgres import PostgresStore
from langgraph.store.memory import InMemoryStore
import os

class MemoryStorageManager:
    """è®°å¿†å­˜å‚¨ç®¡ç†å™¨ - æ”¯æŒå¤šç§æŒä¹…åŒ–å­˜å‚¨"""
    
    def __init__(self, environment: str = "development"):
        self.environment = environment
        self.storage_type = os.getenv("MEMORY_STORAGE_TYPE", "sqlite").lower()
        self.db_path = os.getenv("MEMORY_DB_PATH", "./data/memory.db")
        self.postgres_url = os.getenv("POSTGRES_URL", "postgresql://user:password@localhost:5432/langgraph_memory")
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(self.db_path), exist_ok=True)
        self._setup_storage()
    
    def _setup_storage(self):
        """æ ¹æ®ç¯å¢ƒå’Œé…ç½®è®¾ç½®å­˜å‚¨"""
        if self.storage_type == "postgres" and self.environment == "production":
            # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨PostgreSQL
            self._sqlite_saver_cm = PostgresSaver.from_conn_string(self.postgres_url)
            self.short_term_storage = self._sqlite_saver_cm.__enter__()
            
            self._sqlite_store_cm = PostgresStore.from_conn_string(self.postgres_url)
            self.long_term_storage = self._sqlite_store_cm.__enter__()
            
        elif self.storage_type == "sqlite":
            # ä½¿ç”¨SQLiteæŒä¹…åŒ–å­˜å‚¨
            self._sqlite_saver_cm = SqliteSaver.from_conn_string(self.db_path)
            self.short_term_storage = self._sqlite_saver_cm.__enter__()
            
            self._sqlite_store_cm = SqliteStore.from_conn_string(self.db_path)
            self.long_term_storage = self._sqlite_store_cm.__enter__()
            
        else:
            # å¼€å‘/æµ‹è¯•ç¯å¢ƒä½¿ç”¨å†…å­˜å­˜å‚¨
            self.short_term_storage = InMemorySaver()
            self.long_term_storage = InMemoryStore()

# ä½¿ç”¨ç¤ºä¾‹
storage_manager = MemoryStorageManager("production")

# ç¼–è¯‘æ—¶å¯ç”¨æŒä¹…åŒ–
app = workflow.compile(
    checkpointer=storage_manager.short_term_storage,
    store=storage_manager.long_term_storage
)

# å¸¦ä¼šè¯IDçš„æ‰§è¡Œ
config = {"configurable": {"thread_id": "user_123_session"}}
result = app.invoke({
    "messages": [{"role": "user", "content": "ä½ å¥½ï¼Œæˆ‘æ˜¯å¼ ä¸‰"}]
}, config)

# ç»§ç»­å¯¹è¯ï¼Œæ™ºèƒ½ä½“ä¼šè®°ä½ä¹‹å‰çš„å†…å®¹
result2 = app.invoke({
    "messages": [{"role": "user", "content": "æˆ‘åˆšæ‰è¯´æˆ‘å«ä»€ä¹ˆï¼Ÿ"}]
}, config)
```

#### 4.1.2 ç¯å¢ƒå˜é‡é…ç½®

é€šè¿‡ç¯å¢ƒå˜é‡çµæ´»é…ç½®å­˜å‚¨ç±»å‹ï¼š

```bash
# .env æ–‡ä»¶é…ç½®
MEMORY_STORAGE_TYPE=sqlite          # å­˜å‚¨ç±»å‹: sqlite, postgres, memory
MEMORY_DB_PATH=./data/memory.db     # SQLiteæ•°æ®åº“è·¯å¾„
POSTGRES_URL=postgresql://user:password@localhost:5432/langgraph_memory  # PostgreSQLè¿æ¥å­—ç¬¦ä¸²
```

#### 4.1.2 å¤šç”¨æˆ·ä¼šè¯ç®¡ç†

åœ¨ä¼ä¸šç¯å¢ƒä¸­ï¼ŒåŒä¸€ä¸ªæ™ºèƒ½ä½“éœ€è¦åŒæ—¶ä¸ºå¤šä¸ªç”¨æˆ·æœåŠ¡ã€‚é€šè¿‡ä¸åŒçš„thread_idï¼Œæˆ‘ä»¬å¯ä»¥å®ç°å®Œå…¨éš”ç¦»çš„ä¼šè¯ç®¡ç†ã€‚

```python
# ç”¨æˆ·Açš„å¯¹è¯
user_a_config = {"configurable": {"thread_id": "user_a_session"}}
result_a = app.invoke(user_a_messages, user_a_config)

# ç”¨æˆ·Bçš„å¯¹è¯ï¼ˆå®Œå…¨ç‹¬ç«‹ï¼‰
user_b_config = {"configurable": {"thread_id": "user_b_session"}}
result_b = app.invoke(user_b_messages, user_b_config)
```

#### 4.1.3 å¯¹è¯å†å²ç®¡ç†

å½“å¯¹è¯å˜å¾—å¾ˆé•¿æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç®¡ç†å¯¹è¯å†å²ä»¥å¹³è¡¡æ€§èƒ½å’Œè®°å¿†æ•ˆæœï¼š

```python
def trim_conversation(state: MessagesState) -> MessagesState:
    """ä¿®å‰ªå¯¹è¯å†å²ï¼Œä¿ç•™æœ€è¿‘çš„é‡è¦æ¶ˆæ¯"""
    messages = state["messages"]
    
    # ä¿ç•™ç³»ç»Ÿæ¶ˆæ¯å’Œæœ€è¿‘10è½®å¯¹è¯
    system_messages = [msg for msg in messages if msg.type == "system"]
    recent_messages = messages[-20:]  # æœ€è¿‘10è½®ï¼ˆæ¯è½®2æ¡æ¶ˆæ¯ï¼‰
    
    return {
        "messages": system_messages + recent_messages
    }
```

### 4.2 é•¿æœŸè®°å¿†ï¼šè·¨å¯¹è¯çš„çŸ¥è¯†ç§¯ç´¯

é•¿æœŸè®°å¿†è®©æ™ºèƒ½ä½“èƒ½å¤Ÿè·¨å¤šä¸ªå¯¹è¯çº¿ç¨‹å…±äº«ä¿¡æ¯ï¼Œå½¢æˆæŒç»­çš„å­¦ä¹ å’Œä¸ªæ€§åŒ–èƒ½åŠ›ã€‚

#### 4.2.1 Storeæœºåˆ¶ï¼šçŸ¥è¯†çš„ç»„ç»‡ä¸å­˜å‚¨

LangGraphçš„é•¿æœŸè®°å¿†é€šè¿‡Storeæœºåˆ¶å®ç°ï¼Œä¸çŸ­æœŸè®°å¿†çš„Checkpointerä¸åŒï¼ŒStoreä¸“é—¨ç”¨äºè·¨ä¼šè¯çš„æ•°æ®æŒä¹…åŒ–ã€‚

```python
def save_user_preference(state, config, *, store):
    """ä¿å­˜ç”¨æˆ·åå¥½åˆ°é•¿æœŸè®°å¿†"""
    user_id = config["configurable"]["user_id"]
    namespace = ("user_preferences", user_id)
    
    last_message = state["messages"][-1].content
    if "æˆ‘å–œæ¬¢" in last_message:
        # æå–åå¥½ä¿¡æ¯
        preference = last_message.replace("æˆ‘å–œæ¬¢", "").strip()
        store.put(namespace, "preference", {
            "preference": preference,
            "timestamp": datetime.now().isoformat()
        })
        print(f"å·²ä¿å­˜ç”¨æˆ·åå¥½: {preference}")
    
    return state

def retrieve_user_preference(state, config, *, store):
    """æ£€ç´¢ç”¨æˆ·åå¥½"""
    user_id = config["configurable"]["user_id"]
    namespace = ("user_preferences", user_id)
    
    try:
        preference_data = store.get(namespace, "preference")
        if preference_data:
            preference = preference_data.value["preference"]
            print(f"æ£€ç´¢åˆ°ç”¨æˆ·åå¥½: {preference}")
            return {
                **state,
                "user_preference": preference
            }
    except Exception as e:
        print(f"æ£€ç´¢åå¥½å¤±è´¥: {e}")
    
    return state

# ä½¿ç”¨ç¤ºä¾‹
storage_manager = MemoryStorageManager("development")

# æ˜¾ç¤ºå­˜å‚¨é…ç½®ä¿¡æ¯
storage_info = storage_manager.get_storage_info()
print("ğŸ“Š å­˜å‚¨é…ç½®ä¿¡æ¯:")
for key, value in storage_info.items():
    if value:
        print(f"  â€¢ {key}: {value}")

print("\nğŸ’¡ æç¤º: å¯é€šè¿‡ç¯å¢ƒå˜é‡é…ç½®å­˜å‚¨ç±»å‹:")
print("  â€¢ MEMORY_STORAGE_TYPE=sqlite (é»˜è®¤)")
print("  â€¢ MEMORY_STORAGE_TYPE=postgres")
print("  â€¢ MEMORY_STORAGE_TYPE=memory")
```

#### 4.2.2 è¯­ä¹‰æœç´¢ï¼šæ™ºèƒ½çš„è®°å¿†æ£€ç´¢

**ä»€ä¹ˆæ˜¯è¯­ä¹‰æœç´¢ï¼Ÿ**

ä¼ ç»Ÿçš„å…³é”®è¯æœç´¢åªèƒ½æ‰¾åˆ°åŒ…å«ç‰¹å®šè¯æ±‡çš„å†…å®¹ï¼Œè€Œè¯­ä¹‰æœç´¢èƒ½å¤Ÿç†è§£å†…å®¹çš„å«ä¹‰ã€‚ä¾‹å¦‚ï¼Œå½“ç”¨æˆ·è¯¢é—®"æˆ‘ä¸Šæ¬¡è¯´çš„é‚£ä¸ªé¡¹ç›®æ€ä¹ˆæ ·äº†ï¼Ÿ"æ—¶ï¼Œè¯­ä¹‰æœç´¢å¯ä»¥æ‰¾åˆ°ä¹‹å‰å…³äº"è½¯ä»¶å¼€å‘é¡¹ç›®"ã€"äº§å“è¿­ä»£è®¡åˆ’"ç­‰ç›¸å…³çš„è®°å¿†ï¼Œå³ä½¿è¿™äº›è®°å¿†ä¸­æ²¡æœ‰ç›´æ¥åŒ…å«"é¡¹ç›®"è¿™ä¸ªè¯ã€‚

**ä¸ºä»€ä¹ˆéœ€è¦è¯­ä¹‰æœç´¢ï¼Ÿ**

åœ¨ä¼ä¸šçº§æ™ºèƒ½ä½“åº”ç”¨ä¸­ï¼Œç”¨æˆ·çš„è¡¨è¾¾æ–¹å¼å¤šæ ·åŒ–ï¼ŒåŒä¸€ä¸ªæ¦‚å¿µå¯èƒ½æœ‰å¤šç§è¡¨è¿°ã€‚è¯­ä¹‰æœç´¢è®©æ™ºèƒ½ä½“èƒ½å¤Ÿï¼š

1. **ç†è§£åŒä¹‰è¯**ï¼šå°†"å®¢æˆ·"ã€"ç”¨æˆ·"ã€"æ¶ˆè´¹è€…"è§†ä¸ºç›¸å…³æ¦‚å¿µ
2. **è·¨è¯­è¨€ç†è§£**ï¼šæ”¯æŒä¸­è‹±æ–‡æ··åˆçš„è®°å¿†æ£€ç´¢
3. **ä¸Šä¸‹æ–‡å…³è”**ï¼šåŸºäºè¯­ä¹‰ç›¸ä¼¼æ€§æ‰¾åˆ°ç›¸å…³çš„å†å²å¯¹è¯
4. **æ™ºèƒ½æ¨è**ï¼šä¸»åŠ¨æä¾›å¯èƒ½ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯

```python
from langchain_openai import OpenAIEmbeddings

# åˆ›å»ºæ”¯æŒè¯­ä¹‰æœç´¢çš„å­˜å‚¨ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èä½¿ç”¨æ•°æ®åº“å­˜å‚¨ï¼‰
embeddings = OpenAIEmbeddings()

# ç”Ÿäº§ç¯å¢ƒé…ç½®
if os.getenv("ENVIRONMENT") == "production":
    store = PostgresStore.from_conn_string(
        "postgresql://user:password@localhost:5432/langgraph_memory",
        embedding_function=embeddings
    )
else:
    # å¼€å‘ç¯å¢ƒé…ç½®ï¼ˆæ³¨æ„ï¼šInMemoryStoreé‡å¯åæ•°æ®ä¸¢å¤±ï¼‰
    store = InMemoryStore(embedding_function=embeddings)

def retrieve_relevant_memories(state, config, *, store):
    """æ£€ç´¢ç›¸å…³çš„é•¿æœŸè®°å¿†"""
    user_id = config["configurable"]["user_id"]
    namespace = ("user_memories", user_id)
    
    # åŸºäºå½“å‰æ¶ˆæ¯å†…å®¹æœç´¢ç›¸å…³è®°å¿†
    current_query = state["messages"][-1].content
    print(f"æ­£åœ¨æœç´¢ä¸ '{current_query}' ç›¸å…³çš„è®°å¿†...")
    
    relevant_memories = store.search(
        namespace, 
        query=current_query,
        limit=5  # è¿”å›æœ€ç›¸å…³çš„5æ¡è®°å¿†
    )
    
    # å°†ç›¸å…³è®°å¿†æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­
    memory_context = "\n".join([
        f"ç›¸å…³è®°å¿† {i+1}: {item.value['content']} (ç›¸å…³åº¦: {item.score:.2f})" 
        for i, item in enumerate(relevant_memories)
    ])
    
    print(f"æ‰¾åˆ° {len(relevant_memories)} æ¡ç›¸å…³è®°å¿†")
    
    return {
        **state,
        "memory_context": memory_context
    }

def semantic_memory_search_example():
    """4.2.2 è¯­ä¹‰æœç´¢ç¤ºä¾‹"""
    print("\n=== 4.2.2 è¯­ä¹‰æœç´¢æ¼”ç¤º ===")
    
    # æ¨¡æ‹Ÿå­˜å‚¨ä¸€äº›è®°å¿†
    sample_memories = [
        {"content": "ç”¨æˆ·å¼ ä¸‰æ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œå–œæ¬¢Pythonç¼–ç¨‹", "topic": "personal_info"},
        {"content": "å¼ ä¸‰æ­£åœ¨å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™é¡¹ç›®", "topic": "project"},
        {"content": "é¡¹ç›®ä½¿ç”¨Djangoæ¡†æ¶å’ŒPostgreSQLæ•°æ®åº“", "topic": "technology"},
        {"content": "ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ å’ŒAIæŠ€æœ¯å¾ˆæ„Ÿå…´è¶£", "topic": "interests"},
        {"content": "å¼ ä¸‰çš„å›¢é˜Ÿæœ‰5ä¸ªäººï¼Œé‡‡ç”¨æ•æ·å¼€å‘æ¨¡å¼", "topic": "team"}
    ]
    
    print("ğŸ“ å·²å­˜å‚¨çš„è®°å¿†å†…å®¹:")
    for i, memory in enumerate(sample_memories, 1):
        print(f"  {i}. {memory['content']}")
    
    # æ¨¡æ‹Ÿä¸åŒçš„æŸ¥è¯¢
    test_queries = [
        "å¼ ä¸‰æ˜¯åšä»€ä¹ˆå·¥ä½œçš„ï¼Ÿ",          # åº”è¯¥æ‰¾åˆ°ä¸ªäººä¿¡æ¯
        "ä»–åœ¨å¼€å‘ä»€ä¹ˆäº§å“ï¼Ÿ",            # åº”è¯¥æ‰¾åˆ°é¡¹ç›®ç›¸å…³
        "ç”¨ä»€ä¹ˆæŠ€æœ¯æ ˆï¼Ÿ",               # åº”è¯¥æ‰¾åˆ°æŠ€æœ¯ç›¸å…³
        "å›¢é˜Ÿè§„æ¨¡å¦‚ä½•ï¼Ÿ",               # åº”è¯¥æ‰¾åˆ°å›¢é˜Ÿä¿¡æ¯
        "å¯¹äººå·¥æ™ºèƒ½æœ‰ä»€ä¹ˆçœ‹æ³•ï¼Ÿ"         # åº”è¯¥æ‰¾åˆ°å…´è¶£ç›¸å…³
    ]
    
    print("\nğŸ” è¯­ä¹‰æœç´¢æµ‹è¯•:")
    for query in test_queries:
        print(f"\næŸ¥è¯¢: '{query}'")
        print("é¢„æœŸä¼šæ‰¾åˆ°çš„ç›¸å…³è®°å¿†:")
        
        # è¿™é‡Œæ˜¯æ¨¡æ‹Ÿè¯­ä¹‰æœç´¢çš„ç»“æœ
        if "å·¥ä½œ" in query or "åšä»€ä¹ˆ" in query:
            print("  âœ… ç”¨æˆ·å¼ ä¸‰æ˜¯è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œå–œæ¬¢Pythonç¼–ç¨‹")
        elif "äº§å“" in query or "å¼€å‘ä»€ä¹ˆ" in query:
            print("  âœ… å¼ ä¸‰æ­£åœ¨å¼€å‘ä¸€ä¸ªç”µå•†ç½‘ç«™é¡¹ç›®")
        elif "æŠ€æœ¯" in query:
            print("  âœ… é¡¹ç›®ä½¿ç”¨Djangoæ¡†æ¶å’ŒPostgreSQLæ•°æ®åº“")
        elif "å›¢é˜Ÿ" in query:
            print("  âœ… å¼ ä¸‰çš„å›¢é˜Ÿæœ‰5ä¸ªäººï¼Œé‡‡ç”¨æ•æ·å¼€å‘æ¨¡å¼")
        elif "äººå·¥æ™ºèƒ½" in query or "AI" in query:
            print("  âœ… ç”¨æˆ·å¯¹æœºå™¨å­¦ä¹ å’ŒAIæŠ€æœ¯å¾ˆæ„Ÿå…´è¶£")
    
    print("\nğŸ’¡ è¯­ä¹‰æœç´¢çš„ä¼˜åŠ¿:")
    print("  â€¢ å³ä½¿æŸ¥è¯¢è¯ä¸è®°å¿†å†…å®¹ä¸å®Œå…¨åŒ¹é…ï¼Œä¹Ÿèƒ½æ‰¾åˆ°ç›¸å…³ä¿¡æ¯")
    print("  â€¢ æ”¯æŒè‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼Œç”¨æˆ·ä½“éªŒæ›´å¥½")
    print("  â€¢ èƒ½å¤Ÿç†è§£æ¦‚å¿µä¹‹é—´çš„å…³è”æ€§")
    print("  â€¢ æä¾›ç›¸å…³åº¦è¯„åˆ†ï¼Œå¸®åŠ©æ’åºç»“æœ")
```

#### 4.2.3 è®°å¿†çš„ç±»å‹ä¸ç»„ç»‡

**ä»€ä¹ˆæ˜¯è®°å¿†ç±»å‹ï¼Ÿ**

åœ¨è®¤çŸ¥ç§‘å­¦ä¸­ï¼Œäººç±»çš„é•¿æœŸè®°å¿†è¢«åˆ†ä¸ºå‡ ç§ä¸åŒç±»å‹ï¼Œæ¯ç§ç±»å‹å­˜å‚¨ä¸åŒæ€§è´¨çš„ä¿¡æ¯ã€‚åœ¨ä¼ä¸šçº§æ™ºèƒ½ä½“ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å€Ÿé‰´è¿™ç§åˆ†ç±»æ–¹æ³•æ¥æ›´å¥½åœ°ç»„ç»‡å’Œç®¡ç†æ™ºèƒ½ä½“çš„è®°å¿†ã€‚

**ä¸ºä»€ä¹ˆè¦åŒºåˆ†è®°å¿†ç±»å‹ï¼Ÿ**

ä¸åŒç±»å‹çš„è®°å¿†æœ‰ä¸åŒçš„ç‰¹ç‚¹å’Œç”¨é€”ï¼š

- **æ£€ç´¢æ–¹å¼ä¸åŒ**ï¼šæœ‰äº›è®°å¿†éœ€è¦ç²¾ç¡®åŒ¹é…ï¼Œæœ‰äº›éœ€è¦æ¨¡ç³ŠæŸ¥æ‰¾
- **æ›´æ–°é¢‘ç‡ä¸åŒ**ï¼šäº‹å®æ€§ä¿¡æ¯ç›¸å¯¹ç¨³å®šï¼Œç»å†æ€§ä¿¡æ¯ç»å¸¸å˜åŒ–
- **åº”ç”¨åœºæ™¯ä¸åŒ**ï¼šä¸ªæ€§åŒ–æ¨èéœ€è¦åå¥½ä¿¡æ¯ï¼Œé—®é¢˜è§£å†³éœ€è¦ç»éªŒæ¨¡å¼

#### **4.2.3.1 è¯­ä¹‰è®°å¿†ï¼šäº‹å®æ€§çŸ¥è¯†**

è¯­ä¹‰è®°å¿†å­˜å‚¨çš„æ˜¯**å®¢è§‚äº‹å®å’Œæ¦‚å¿µæ€§çŸ¥è¯†**ï¼Œè¿™ç±»ä¿¡æ¯é€šå¸¸æ¯”è¾ƒç¨³å®šï¼Œä¸ä¼šé¢‘ç¹å˜åŒ–ã€‚

**é€‚ç”¨åœºæ™¯ï¼š**

- ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼ˆå§“åã€èŒä¸šã€è”ç³»æ–¹å¼ï¼‰
- ä¸šåŠ¡è§„åˆ™å’Œæ”¿ç­–
- äº§å“åŠŸèƒ½å’ŒæŠ€æœ¯è§„æ ¼
- ç»„ç»‡æ¶æ„å’Œäººå‘˜å…³ç³»

```python
def store_semantic_memory_example():
    """è¯­ä¹‰è®°å¿†å­˜å‚¨ç¤ºä¾‹"""
    print("\n=== 4.2.3.1 è¯­ä¹‰è®°å¿†ï¼šäº‹å®æ€§çŸ¥è¯† ===")
    
    # ç”¨æˆ·åŸºæœ¬ä¿¡æ¯
    user_facts = {
        "name": "å¼ ä¸‰",
        "occupation": "è½¯ä»¶å·¥ç¨‹å¸ˆ", 
        "department": "æŠ€æœ¯éƒ¨",
        "level": "é«˜çº§å·¥ç¨‹å¸ˆ",
        "preferences": {
            "communication_style": "ç®€æ´ç›´æ¥",
            "language": "ä¸­æ–‡",
            "notification_time": "09:00-18:00"
        },
        "skills": ["Python", "JavaScript", "æ•°æ®åº“è®¾è®¡", "ç³»ç»Ÿæ¶æ„"]
    }
    
    # å­˜å‚¨åˆ°è¯­ä¹‰è®°å¿†å‘½åç©ºé—´
    # store.put(("semantic", user_id), "user_profile", user_facts)
    
    print("ğŸ“‹ å­˜å‚¨çš„è¯­ä¹‰è®°å¿†:")
    print(f"  â€¢ åŸºæœ¬ä¿¡æ¯: {user_facts['name']} - {user_facts['occupation']}")
    print(f"  â€¢ æ²Ÿé€šåå¥½: {user_facts['preferences']['communication_style']}")
    print(f"  â€¢ æŠ€èƒ½æ ‡ç­¾: {', '.join(user_facts['skills'])}")
    
    # ä¸šåŠ¡è§„åˆ™ç¤ºä¾‹
    business_rules = {
        "approval_limit": {
            "junior": 1000,
            "senior": 10000,
            "manager": 50000
        },
        "working_hours": "09:00-18:00",
        "emergency_contact": "IT Support: ext-911"
    }
    
    # store.put(("semantic", "business"), "rules", business_rules)
    
    print("ğŸ’¼ ä¸šåŠ¡è§„åˆ™è®°å¿†:")
    print(f"  â€¢ å®¡æ‰¹æƒé™: é«˜çº§å·¥ç¨‹å¸ˆå¯å®¡æ‰¹ {business_rules['approval_limit']['senior']} å…ƒä»¥ä¸‹")
    print(f"  â€¢ å·¥ä½œæ—¶é—´: {business_rules['working_hours']}")
```

#### **4.2.3.2 æƒ…èŠ‚è®°å¿†ï¼šå…·ä½“ç»å†**

æƒ…èŠ‚è®°å¿†å­˜å‚¨çš„æ˜¯**å…·ä½“çš„äº‹ä»¶å’Œç»å†**ï¼ŒåŒ…å«æ—¶é—´ã€åœ°ç‚¹ã€å‚ä¸è€…å’Œå‘ç”Ÿçš„äº‹æƒ…ç­‰è¯¦ç»†ä¿¡æ¯ã€‚

**é€‚ç”¨åœºæ™¯ï¼š**

- ç”¨æˆ·çš„å†å²å¯¹è¯è®°å½•
- é‡è¦çš„ä¸šåŠ¡äº‹ä»¶
- é—®é¢˜å¤„ç†è¿‡ç¨‹
- å†³ç­–åˆ¶å®šç»è¿‡

```python
def store_episodic_memory_example():
    """æƒ…èŠ‚è®°å¿†å­˜å‚¨ç¤ºä¾‹"""
    print("\n=== 4.2.3.2 æƒ…èŠ‚è®°å¿†ï¼šå…·ä½“ç»å† ===")
    
    # å…·ä½“çš„äº¤äº’ç»å†
    episode_1 = {
        "timestamp": "2025-01-15T10:30:00",
        "context": "ç”¨æˆ·å’¨è¯¢é¡¹ç›®è¿›åº¦",
        "participants": ["å¼ ä¸‰", "é¡¹ç›®ç»ç†AI"],
        "action": "æä¾›äº†è¯¦ç»†çš„è¿›åº¦æŠ¥å‘Š",
        "outcome": "ç”¨æˆ·è¡¨ç¤ºæ»¡æ„",
        "details": {
            "project_name": "ç”µå•†ç½‘ç«™é‡æ„",
            "completion_rate": "75%",
            "next_milestone": "2025-01-20"
        }
    }
    
    episode_2 = {
        "timestamp": "2025-01-16T14:20:00",
        "context": "æŠ€æœ¯é—®é¢˜æ±‚åŠ©",
        "participants": ["å¼ ä¸‰", "æŠ€æœ¯æ”¯æŒAI"],
        "action": "ååŠ©è§£å†³æ•°æ®åº“è¿æ¥é—®é¢˜",
        "outcome": "é—®é¢˜å·²è§£å†³",
        "details": {
            "problem_type": "æ•°æ®åº“è¿æ¥è¶…æ—¶",
            "solution": "è°ƒæ•´è¿æ¥æ± é…ç½®",
            "resolution_time": "30åˆ†é’Ÿ"
        }
    }
    
    episodes = [episode_1, episode_2]
    
    print("ğŸ“… å­˜å‚¨çš„æƒ…èŠ‚è®°å¿†:")
    for i, episode in enumerate(episodes, 1):
        print(f"\n  æƒ…èŠ‚ {i}:")
        print(f"    æ—¶é—´: {episode['timestamp']}")
        print(f"    åœºæ™¯: {episode['context']}")
        print(f"    è¡ŒåŠ¨: {episode['action']}")
        print(f"    ç»“æœ: {episode['outcome']}")
        
        # æ¨¡æ‹Ÿå­˜å‚¨
        episode_id = f"episode_{episode['timestamp']}"
        # store.put(("episodic", user_id), episode_id, episode)
    
    print("\nğŸ’¡ æƒ…èŠ‚è®°å¿†çš„ä»·å€¼:")
    print("  â€¢ å¸®åŠ©æ™ºèƒ½ä½“äº†è§£ç”¨æˆ·çš„å†å²éœ€æ±‚æ¨¡å¼")
    print("  â€¢ ä¸ºç±»ä¼¼é—®é¢˜æä¾›è§£å†³æ–¹æ¡ˆå‚è€ƒ")
    print("  â€¢ å»ºç«‹ç”¨æˆ·ä¸ç³»ç»Ÿçš„äº¤äº’å†å²æ¡£æ¡ˆ")
```

#### **4.2.3.3 ç¨‹åºè®°å¿†ï¼šæ“ä½œæ–¹å¼**

ç¨‹åºè®°å¿†å­˜å‚¨çš„æ˜¯**æ“ä½œæ–¹æ³•å’Œå¤„ç†æ¨¡å¼**ï¼Œæ˜¯æ™ºèƒ½ä½“ç§¯ç´¯çš„"ç»éªŒçŸ¥è¯†"ã€‚

**é€‚ç”¨åœºæ™¯ï¼š**

- æˆåŠŸçš„é—®é¢˜è§£å†³æ–¹æ¡ˆ
- æœ‰æ•ˆçš„æ²Ÿé€šæ¨¡å¼
- ä¼˜åŒ–çš„å·¥ä½œæµç¨‹
- æœ€ä½³å®è·µå’ŒæŠ€å·§

```python
def store_procedural_memory_example():
    """ç¨‹åºè®°å¿†å­˜å‚¨ç¤ºä¾‹"""
    print("\n=== 4.2.3.3 ç¨‹åºè®°å¿†ï¼šæ“ä½œæ–¹å¼ ===")
    
    # æˆåŠŸçš„å¤„ç†æ¨¡å¼
    procedure_1 = {
        "situation": "ç”¨æˆ·è¯¢é—®æŠ€æœ¯é—®é¢˜",
        "approach": [
            "1. ç¡®è®¤å…·ä½“çš„æŠ€æœ¯æ ˆå’Œç¯å¢ƒ",
            "2. è¯¢é—®é”™è¯¯ä¿¡æ¯å’Œå¤ç°æ­¥éª¤", 
            "3. æä¾›åˆ†æ­¥éª¤è§£å†³æ–¹æ¡ˆ",
            "4. ç¡®è®¤é—®é¢˜æ˜¯å¦è§£å†³"
        ],
        "effectiveness": "é«˜",
        "success_rate": 0.9,
        "avg_resolution_time": "15åˆ†é’Ÿ"
    }
    
    procedure_2 = {
        "situation": "ç”¨æˆ·éœ€è¦é¡¹ç›®è¿›åº¦ä¿¡æ¯",
        "approach": [
            "1. è¯†åˆ«å…·ä½“çš„é¡¹ç›®åç§°",
            "2. æŸ¥è¯¢æœ€æ–°çš„è¿›åº¦æ•°æ®",
            "3. æä¾›å…³é”®é‡Œç¨‹ç¢‘å’Œæ—¶é—´èŠ‚ç‚¹",
            "4. ä¸»åŠ¨æåŠæ½œåœ¨é£é™©æˆ–å»¶æœŸå› ç´ "
        ],
        "effectiveness": "é«˜",
        "success_rate": 0.95,
        "avg_satisfaction": 4.7
    }
    
    procedures = [procedure_1, procedure_2]
    
    print("ğŸ”§ å­˜å‚¨çš„ç¨‹åºè®°å¿†:")
    for i, procedure in enumerate(procedures, 1):
        print(f"\n  å¤„ç†æ¨¡å¼ {i}:")
        print(f"    é€‚ç”¨åœºæ™¯: {procedure['situation']}")
        print(f"    å¤„ç†æ­¥éª¤:")
        for step in procedure['approach']:
            print(f"      {step}")
        print(f"    æœ‰æ•ˆæ€§: {procedure['effectiveness']} (æˆåŠŸç‡: {procedure.get('success_rate', 'N/A')})")
        
        # æ¨¡æ‹Ÿå­˜å‚¨
        procedure_id = f"procedure_{i}"
        # store.put(("procedural", user_id), procedure_id, procedure)
    
    print("\nğŸ’ª ç¨‹åºè®°å¿†çš„ä¼˜åŠ¿:")
    print("  â€¢ æé«˜é—®é¢˜è§£å†³çš„æ•ˆç‡å’Œä¸€è‡´æ€§")
    print("  â€¢ ç§¯ç´¯å’Œä¼ æ‰¿æœ€ä½³å®è·µ")
    print("  â€¢ æ”¯æŒæ™ºèƒ½ä½“çš„è‡ªæˆ‘ä¼˜åŒ–å’Œå­¦ä¹ ")
    print("  â€¢ ä¸ºæ–°åœºæ™¯æä¾›ç»éªŒå‚è€ƒ")

# ç»¼åˆç¤ºä¾‹ï¼šå¦‚ä½•åœ¨å®é™…åº”ç”¨ä¸­ä½¿ç”¨ä¸åŒç±»å‹çš„è®°å¿†
def integrated_memory_usage_example():
    """ç»¼åˆè®°å¿†ä½¿ç”¨ç¤ºä¾‹"""
    print("\n=== 4.2.3.4 ç»¼åˆè®°å¿†åº”ç”¨åœºæ™¯ ===")
    
    print("ğŸ¯ åœºæ™¯ï¼šç”¨æˆ·å¼ ä¸‰å†æ¬¡è¯¢é—®æŠ€æœ¯é—®é¢˜")
    
    print("\n1ï¸âƒ£ æ£€ç´¢è¯­ä¹‰è®°å¿† - äº†è§£ç”¨æˆ·èƒŒæ™¯:")
    print("  âœ… å¼ ä¸‰æ˜¯é«˜çº§è½¯ä»¶å·¥ç¨‹å¸ˆï¼Œæ“…é•¿Pythonå’ŒJavaScript")
    print("  âœ… åå¥½ç®€æ´ç›´æ¥çš„æ²Ÿé€šæ–¹å¼")
    
    print("\n2ï¸âƒ£ æ£€ç´¢æƒ…èŠ‚è®°å¿† - å›é¡¾å†å²äº¤äº’:")
    print("  âœ… ä¸Šæ¬¡å¸®åŠ©è§£å†³äº†æ•°æ®åº“è¿æ¥é—®é¢˜")
    print("  âœ… ç”¨æˆ·å¯¹æŠ€æœ¯è§£å†³æ–¹æ¡ˆæ¥å—åº¦é«˜")
    
    print("\n3ï¸âƒ£ åº”ç”¨ç¨‹åºè®°å¿† - é€‰æ‹©å¤„ç†æ–¹å¼:")
    print("  âœ… é‡‡ç”¨æŠ€æœ¯é—®é¢˜å¤„ç†æ¨¡å¼")
    print("  âœ… ç›´æ¥è¯¢é—®æŠ€æœ¯ç»†èŠ‚ï¼Œè·³è¿‡åŸºç¡€è§£é‡Š")
    
    print("\nğŸš€ æ™ºèƒ½ä½“å“åº”:")
    print("  'å¼ ä¸‰ï¼Œæˆ‘çœ‹åˆ°ä½ é‡åˆ°äº†æ–°çš„æŠ€æœ¯é—®é¢˜ã€‚'")
    print("  'åŸºäºä½ çš„æŠ€æœ¯èƒŒæ™¯ï¼Œæˆ‘ç›´æ¥ä¸ºä½ æä¾›è§£å†³æ–¹æ¡ˆã€‚'")
    print("  'è¯·å‘Šè¯‰æˆ‘å…·ä½“çš„é”™è¯¯ä¿¡æ¯å’Œå½“å‰çš„æŠ€æœ¯æ ˆé…ç½®ã€‚'")
    
    print("\nğŸ’¡ è®°å¿†ååŒçš„ä»·å€¼:")
    print("  â€¢ ä¸ªæ€§åŒ–çš„äº¤äº’ä½“éªŒ")
    print("  â€¢ æ›´é«˜æ•ˆçš„é—®é¢˜è§£å†³")
    print("  â€¢ æŒç»­ä¼˜åŒ–çš„æœåŠ¡è´¨é‡")
```

### 4.3 è®°å¿†ç³»ç»Ÿçš„æœ€ä½³å®è·µ

#### 4.3.1 å­˜å‚¨é€‰æ‹©ç­–ç•¥

é€‰æ‹©åˆé€‚çš„å­˜å‚¨æœºåˆ¶å¯¹è®°å¿†ç³»ç»Ÿçš„æ€§èƒ½å’Œå¯é æ€§è‡³å…³é‡è¦ï¼š

```python
class MemoryStorageManager:
    """è®°å¿†å­˜å‚¨ç®¡ç†å™¨"""
    
    def __init__(self, environment: str = "development"):
        self.environment = environment
        self.short_term_storage = None  # Checkpointer
        self.long_term_storage = None   # Store
        self._setup_storage()
    
    def _setup_storage(self):
        """æ ¹æ®ç¯å¢ƒé…ç½®å­˜å‚¨"""
        if self.environment == "production":
            # ç”Ÿäº§ç¯å¢ƒï¼šä½¿ç”¨æ•°æ®åº“æŒä¹…åŒ–
            from langgraph.checkpoint.postgres import PostgresSaver
            from langgraph.store.postgres import PostgresStore
            
            db_url = os.getenv("DATABASE_URL")
            
            # çŸ­æœŸè®°å¿†ï¼šä¼šè¯çŠ¶æ€æŒä¹…åŒ–
            self.short_term_storage = PostgresSaver.from_conn_string(db_url)
            
            # é•¿æœŸè®°å¿†ï¼šè·¨ä¼šè¯æ•°æ®æŒä¹…åŒ–
            self.long_term_storage = PostgresStore.from_conn_string(
                db_url,
                embedding_function=OpenAIEmbeddings()
            )
            
        elif self.environment == "development":
            # å¼€å‘ç¯å¢ƒï¼šå¿«é€Ÿæµ‹è¯•
            from langgraph.checkpoint.memory import InMemorySaver
            from langgraph.store.memory import InMemoryStore
            
            self.short_term_storage = InMemorySaver()
            self.long_term_storage = InMemoryStore(
                embedding_function=OpenAIEmbeddings()
            )
            
        elif self.environment == "testing":
            # æµ‹è¯•ç¯å¢ƒï¼šå¯æ§çš„ä¸´æ—¶å­˜å‚¨
            from langgraph.checkpoint.sqlite import SqliteSaver
            from langgraph.store.memory import InMemoryStore
            
            self.short_term_storage = SqliteSaver.from_conn_string(":memory:")
            self.long_term_storage = InMemoryStore()

# ä½¿ç”¨ç¤ºä¾‹
storage_manager = MemoryStorageManager(os.getenv("ENVIRONMENT", "development"))

app = workflow.compile(
    checkpointer=storage_manager.short_term_storage,
    store=storage_manager.long_term_storage
)
```

#### 4.3.2 è®°å¿†æ›´æ–°ç­–ç•¥

**ä»€ä¹ˆæ˜¯è®°å¿†æ›´æ–°ç­–ç•¥ï¼Ÿ**

è®°å¿†æ›´æ–°ç­–ç•¥å†³å®šäº†æ™ºèƒ½ä½“å¦‚ä½•ä»æ–°çš„äº¤äº’ä¸­å­¦ä¹ å¹¶æ›´æ–°å·²æœ‰çš„è®°å¿†ã€‚å¥½çš„æ›´æ–°ç­–ç•¥èƒ½å¤Ÿç¡®ä¿è®°å¿†ç³»ç»Ÿæ—¢èƒ½ä¿æŒå‡†ç¡®æ€§ï¼Œåˆèƒ½é€‚åº”å˜åŒ–ã€‚

**ä¸ºä»€ä¹ˆéœ€è¦è®°å¿†æ›´æ–°ç­–ç•¥ï¼Ÿ**

1. **ä¿¡æ¯çš„æ—¶æ•ˆæ€§**ï¼šç”¨æˆ·çš„åå¥½ã€çŠ¶æ€å¯èƒ½ä¼šå‘ç”Ÿå˜åŒ–
2. **çŸ¥è¯†çš„å®Œå–„æ€§**ï¼šæ–°çš„äº¤äº’å¯èƒ½è¡¥å……æˆ–çº æ­£å·²æœ‰ä¿¡æ¯
3. **ç³»ç»Ÿçš„å­¦ä¹ æ€§**ï¼šæ™ºèƒ½ä½“éœ€è¦ä»ç»éªŒä¸­ä¸æ–­ä¼˜åŒ–è¡¨ç°
4. **å­˜å‚¨çš„æ•ˆç‡æ€§**ï¼šé¿å…é‡å¤å’Œå†—ä½™çš„è®°å¿†æ¡ç›®

#### **4.3.2.1 å¢é‡æ›´æ–°ç­–ç•¥**

```python
def update_memory_background(conversation_history, user_id, store):
    """åœ¨åå°æ›´æ–°è®°å¿†ï¼Œä¸å½±å“å¯¹è¯æµç¨‹"""
    print("\n=== 4.3.2.1 å¢é‡æ›´æ–°ç­–ç•¥æ¼”ç¤º ===")
    
    # åˆ†æå¯¹è¯ï¼Œæå–é‡è¦ä¿¡æ¯
    important_facts = extract_facts(conversation_history)
    
    print(f"ğŸ“Š ä»å¯¹è¯ä¸­æå–åˆ° {len(important_facts)} æ¡é‡è¦ä¿¡æ¯")
    
    # æ›´æ–°æˆ–åˆ›å»ºæ–°çš„è®°å¿†æ¡ç›®
    for fact in important_facts:
        namespace = ("semantic", user_id)
        existing = store.get(namespace, fact["key"])
        
        if existing:
            print(f"ğŸ”„ æ›´æ–°å·²å­˜åœ¨çš„è®°å¿†: {fact['key']}")
            # åˆå¹¶æ–°æ—§ä¿¡æ¯
            updated_fact = merge_facts(existing.value, fact)
            store.put(namespace, fact["key"], updated_fact)
        else:
            print(f"â• åˆ›å»ºæ–°çš„è®°å¿†æ¡ç›®: {fact['key']}")
            # åˆ›å»ºæ–°è®°å¿†
            store.put(namespace, fact["key"], fact)

def extract_facts(conversation_history):
    """ä»å¯¹è¯å†å²ä¸­æå–é‡è¦äº‹å®"""
    # è¿™é‡Œæ˜¯ç®€åŒ–çš„ç¤ºä¾‹ï¼Œå®é™…åº”ç”¨ä¸­å¯èƒ½ä½¿ç”¨NLPæŠ€æœ¯
    facts = []
    
    for message in conversation_history:
        content = message.get("content", "")
        
        # æå–ç”¨æˆ·åå¥½
        if "æˆ‘å–œæ¬¢" in content:
            preference = content.split("æˆ‘å–œæ¬¢")[1].strip()
            facts.append({
                "key": "user_preferences",
                "type": "preference",
                "value": preference,
                "timestamp": message.get("timestamp", "")
            })
        
        # æå–æŠ€èƒ½ä¿¡æ¯
        if "æˆ‘ä¼š" in content or "æˆ‘æ“…é•¿" in content:
            skill = content.replace("æˆ‘ä¼š", "").replace("æˆ‘æ“…é•¿", "").strip()
            facts.append({
                "key": "user_skills",
                "type": "skill",
                "value": skill,
                "timestamp": message.get("timestamp", "")
            })
        
        # æå–é¡¹ç›®ä¿¡æ¯
        if "é¡¹ç›®" in content:
            facts.append({
                "key": "current_projects",
                "type": "project",
                "value": content,
                "timestamp": message.get("timestamp", "")
            })
    
    return facts

def merge_facts(existing_fact, new_fact):
    """åˆå¹¶æ–°æ—§äº‹å®ä¿¡æ¯"""
    print(f"  ğŸ”€ åˆå¹¶ä¿¡æ¯: {existing_fact.get('value', '')} + {new_fact['value']}")
    
    # ä¿ç•™æ—¶é—´æˆ³æœ€æ–°çš„ä¿¡æ¯ä¸ºä¸»
    merged = {
        "value": new_fact["value"],  # æ–°ä¿¡æ¯ä¼˜å…ˆ
        "updated_at": new_fact["timestamp"],
        "previous_value": existing_fact.get("value"),
        "change_history": existing_fact.get("change_history", [])
    }
    
    # è®°å½•å˜æ›´å†å²
    if existing_fact.get("value") != new_fact["value"]:
        change_record = {
            "from": existing_fact.get("value"),
            "to": new_fact["value"],
            "timestamp": new_fact["timestamp"]
        }
        merged["change_history"].append(change_record)
    
    return merged
```

#### **4.3.2.2 ç­–ç•¥æ€§æ›´æ–°æ–¹æ³•**

```python
def strategic_memory_update(state, config, *, store):
    """ç­–ç•¥æ€§è®°å¿†æ›´æ–°"""
    print("\n=== 4.3.2.2 ç­–ç•¥æ€§æ›´æ–°æ–¹æ³• ===")
    
    user_id = config["configurable"]["user_id"]
    current_message = state["messages"][-1].content
    
    # 1. é‡è¦æ€§è¯„ä¼°
    importance_score = assess_importance(current_message)
    print(f"ğŸ“ˆ é‡è¦æ€§è¯„åˆ†: {importance_score}/10")
    
    if importance_score >= 7:
        print("â­ é«˜é‡è¦æ€§ä¿¡æ¯ï¼Œç«‹å³æ›´æ–°è®°å¿†")
        update_immediately = True
    elif importance_score >= 4:
        print("ğŸ“‹ ä¸­ç­‰é‡è¦æ€§ï¼Œæ·»åŠ åˆ°å¾…æ›´æ–°é˜Ÿåˆ—")
        add_to_update_queue(current_message, user_id)
        update_immediately = False
    else:
        print("ğŸ“ ä½é‡è¦æ€§ä¿¡æ¯ï¼Œä»…è®°å½•åˆ°ä¸´æ—¶ç¼“å­˜")
        add_to_temp_cache(current_message, user_id)
        update_immediately = False
    
    # 2. å†²çªæ£€æµ‹
    if update_immediately:
        conflicts = detect_conflicts(current_message, user_id, store)
        if conflicts:
            print(f"âš ï¸ æ£€æµ‹åˆ° {len(conflicts)} ä¸ªæ½œåœ¨å†²çª")
            resolve_conflicts(conflicts, current_message, user_id, store)
        else:
            print("âœ… æ— å†²çªï¼Œç›´æ¥æ›´æ–°")
            update_memory_directly(current_message, user_id, store)
    
    return state

def assess_importance(message_content):
    """è¯„ä¼°ä¿¡æ¯çš„é‡è¦æ€§"""
    importance = 0
    
    # åŸºäºå…³é”®è¯çš„é‡è¦æ€§è¯„ä¼°
    high_importance_keywords = ["åå¥½", "ä¸å–œæ¬¢", "æ”¹å˜", "æ›´æ–°", "é¡¹ç›®", "å·¥ä½œ"]
    medium_importance_keywords = ["æƒ³è¦", "éœ€è¦", "è®¡åˆ’", "ç›®æ ‡"]
    
    for keyword in high_importance_keywords:
        if keyword in message_content:
            importance += 3
    
    for keyword in medium_importance_keywords:
        if keyword in message_content:
            importance += 2
    
    # åŸºäºå¥å­ç»“æ„çš„é‡è¦æ€§
    if "æˆ‘æ˜¯" in message_content or "æˆ‘çš„" in message_content:
        importance += 2
    
    return min(importance, 10)  # æœ€é«˜10åˆ†

def detect_conflicts(new_info, user_id, store):
    """æ£€æµ‹è®°å¿†å†²çª"""
    conflicts = []
    
    # æ£€æŸ¥æ˜¯å¦ä¸ç°æœ‰è®°å¿†å†²çª
    namespace = ("semantic", user_id)
    existing_memories = store.search(namespace, query=new_info, limit=10)
    
    for memory in existing_memories:
        if is_conflicting(new_info, memory.value):
            conflicts.append({
                "existing": memory,
                "new": new_info,
                "conflict_type": "contradiction"
            })
    
    return conflicts

def resolve_conflicts(conflicts, new_info, user_id, store):
    """è§£å†³è®°å¿†å†²çª"""
    print("ğŸ”§ è§£å†³è®°å¿†å†²çª:")
    
    for conflict in conflicts:
        print(f"  å†²çª: {conflict['existing'].value} vs {new_info}")
        
        # åŸºäºæ—¶é—´æˆ³å†³å®šä¿ç•™å“ªä¸ªä¿¡æ¯
        if is_newer_info(new_info, conflict['existing']):
            print("  âœ… æ–°ä¿¡æ¯æ›´æ–°ï¼Œæ›¿æ¢æ—§è®°å¿†")
            namespace = ("semantic", user_id)
            store.put(namespace, conflict['existing'].key, {
                "value": new_info,
                "updated_at": datetime.now().isoformat(),
                "replaced": conflict['existing'].value
            })
        else:
            print("  ğŸ“ æ—§ä¿¡æ¯ä¿ç•™ï¼Œæ–°ä¿¡æ¯ä½œä¸ºå˜æ›´è®°å½•")

def is_conflicting(new_info, existing_info):
    """åˆ¤æ–­ä¿¡æ¯æ˜¯å¦å†²çª"""
    # ç®€åŒ–çš„å†²çªæ£€æµ‹é€»è¾‘
    negative_patterns = ["ä¸å–œæ¬¢", "ä¸è¦", "æ”¹å˜", "ä¸å†"]
    
    for pattern in negative_patterns:
        if pattern in new_info and existing_info.get("value", "") not in new_info:
            return True
    
    return False

def is_newer_info(new_info, existing_memory):
    """åˆ¤æ–­ä¿¡æ¯æ˜¯å¦æ›´æ–°"""
    # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œä¼šæ¯”è¾ƒæ—¶é—´æˆ³
    return True  # ç®€åŒ–ç¤ºä¾‹ï¼Œå‡è®¾æ–°ä¿¡æ¯æ€»æ˜¯æ›´æ–°çš„
```

#### **4.3.2.3 æ›´æ–°ç­–ç•¥çš„æœ€ä½³å®è·µ**

```python
def memory_update_best_practices():
    """è®°å¿†æ›´æ–°çš„æœ€ä½³å®è·µ"""
    print("\n=== 4.3.2.3 è®°å¿†æ›´æ–°æœ€ä½³å®è·µ ===")
    
    practices = {
        "æ—¶æ•ˆæ€§ç®¡ç†": [
            "ä¸ºæ¯æ¡è®°å¿†æ·»åŠ æ—¶é—´æˆ³",
            "å®šæœŸæ¸…ç†è¿‡æœŸä¿¡æ¯",
            "ä¼˜å…ˆä¿ç•™æœ€æ–°çš„å‡†ç¡®ä¿¡æ¯"
        ],
        "å†²çªè§£å†³": [
            "å»ºç«‹æ˜ç¡®çš„ä¼˜å…ˆçº§è§„åˆ™",
            "ä¿ç•™å˜æ›´å†å²è®°å½•",
            "åœ¨ä¸ç¡®å®šæ—¶è¯¢é—®ç”¨æˆ·ç¡®è®¤"
        ],
        "è´¨é‡æ§åˆ¶": [
            "éªŒè¯ä¿¡æ¯çš„ä¸€è‡´æ€§",
            "è¿‡æ»¤ä½è´¨é‡æˆ–é‡å¤ä¿¡æ¯",
            "å®šæœŸè¿›è¡Œè®°å¿†æ•´ç†"
        ],
        "æ€§èƒ½ä¼˜åŒ–": [
            "æ‰¹é‡æ›´æ–°ä»¥æé«˜æ•ˆç‡",
            "ä½¿ç”¨åå°ä»»åŠ¡é¿å…é˜»å¡",
            "å®æ–½è®°å¿†å‹ç¼©å’Œå½’æ¡£"
        ]
    }
    
    for category, items in practices.items():
        print(f"\nğŸ“‹ {category}:")
        for item in items:
            print(f"  â€¢ {item}")
    
    print("\nğŸ’¡ è®°å¿†æ›´æ–°ç­–ç•¥çš„æ ¸å¿ƒåŸåˆ™:")
    print("  1. å‡†ç¡®æ€§ï¼šç¡®ä¿è®°å¿†å†…å®¹çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§")
    print("  2. æ—¶æ•ˆæ€§ï¼šåŠæ—¶æ›´æ–°å˜åŒ–çš„ä¿¡æ¯")
    print("  3. å®Œæ•´æ€§ï¼šä¿æŒè®°å¿†çš„å®Œæ•´æ€§å’Œå…³è”æ€§")
    print("  4. æ•ˆç‡æ€§ï¼šä¼˜åŒ–æ›´æ–°è¿‡ç¨‹çš„æ€§èƒ½")
```

#### 4.3.3 è®°å¿†ç±»å‹å¯¹æ¯”

| è®°å¿†ç±»å‹     | å­˜å‚¨æœºåˆ¶     | ç”Ÿå‘½å‘¨æœŸ | é€‚ç”¨åœºæ™¯             | å­˜å‚¨å»ºè®®                                     |
| ------------ | ------------ | -------- | -------------------- | -------------------------------------------- |
| **çŸ­æœŸè®°å¿†** | Checkpointer | ä¼šè¯çº§åˆ« | å¯¹è¯ä¸Šä¸‹æ–‡ã€ä¸´æ—¶çŠ¶æ€ | å¼€å‘ï¼šInMemorySaver<br />ç”Ÿäº§ï¼šPostgresSaver |
| **é•¿æœŸè®°å¿†** | Store        | è·¨ä¼šè¯   | ç”¨æˆ·åå¥½ã€çŸ¥è¯†ç§¯ç´¯   | å¼€å‘ï¼šInMemoryStore<br/>ç”Ÿäº§ï¼šPostgresStore  |

#### 4.3.4 éšç§å’Œå®‰å…¨è€ƒè™‘

```python
def privacy_filter(memory_data, user_permissions):
    """æ ¹æ®ç”¨æˆ·æƒé™è¿‡æ»¤è®°å¿†æ•°æ®"""
    if user_permissions.get("allow_personal_data", False):
        return memory_data
    else:
        # ç§»é™¤æ•æ„Ÿä¿¡æ¯
        filtered_data = {
            k: v for k, v in memory_data.items() 
            if k not in ["phone", "address", "id_number"]
        }
        return filtered_data

def setup_memory_retention_policy():
    """è®¾ç½®è®°å¿†ä¿ç•™ç­–ç•¥"""
    return {
        "short_term": {
            "max_messages": 50,        # æœ€å¤šä¿ç•™50æ¡æ¶ˆæ¯
            "ttl_days": 7             # 7å¤©åè‡ªåŠ¨æ¸…ç†
        },
        "long_term": {
            "user_preferences": {"ttl_days": 365},  # ç”¨æˆ·åå¥½ä¿ç•™1å¹´
            "interaction_history": {"ttl_days": 30}, # äº¤äº’å†å²ä¿ç•™30å¤©
            "sensitive_data": {"ttl_days": 1}        # æ•æ„Ÿæ•°æ®1å¤©åæ¸…ç†
        }
    }
```

## äº”ã€æ¨¡å‹é›†æˆï¼šçµæ´»çš„AIå¼•æ“é€‰æ‹©

### 5.1 è‡ªå®šä¹‰æ¨¡å‹é…ç½®

åœ¨çº¿ä¸Šç¯å¢ƒä¸­ï¼Œæˆ‘ä»¬å¾€å¾€éœ€è¦ä½¿ç”¨è‡ªå®šä¹‰çš„APIç«¯ç‚¹ã€å¯†é’¥å’Œæ¨¡å‹é…ç½®ã€‚LangGraphæ”¯æŒçµæ´»çš„æ¨¡å‹é›†æˆæ–¹æ¡ˆï¼š

```python
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
import os

class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ï¼Œæ”¯æŒå¤šç§è‡ªå®šä¹‰é…ç½®"""
    
    def __init__(self):
        self.models = {}
    
    def register_openai_model(self, name: str, config: dict):
        """æ³¨å†Œè‡ªå®šä¹‰OpenAIæ¨¡å‹"""
        self.models[name] = ChatOpenAI(
            model=config.get("model", "gpt-4"),
            api_key=config.get("api_key"),
            base_url=config.get("base_url", "https://api.openai.com/v1"),
            temperature=config.get("temperature", 0.1),
            max_tokens=config.get("max_tokens", 4000)
        )
    
    def register_anthropic_model(self, name: str, config: dict):
        """æ³¨å†Œè‡ªå®šä¹‰Anthropicæ¨¡å‹"""
        self.models[name] = ChatAnthropic(
            model=config.get("model", "claude-3-sonnet-20240229"),
            api_key=config.get("api_key"),
            base_url=config.get("base_url"),
            temperature=config.get("temperature", 0.1),
            max_tokens=config.get("max_tokens", 4000)
        )
    
    def get_model(self, name: str):
        """è·å–æŒ‡å®šæ¨¡å‹"""
        return self.models.get(name)

# åˆå§‹åŒ–æ¨¡å‹ç®¡ç†å™¨
model_manager = ModelManager()

# æ³¨å†Œä¼ä¸šå†…éƒ¨çš„OpenAIå…¼å®¹æ¨¡å‹
model_manager.register_openai_model("company_gpt4", {
    "model": "gpt-4-turbo",
    "api_key": os.getenv("COMPANY_API_KEY"),
    "base_url": "https://internal-api.company.com/v1",
    "temperature": 0.1,
    "max_tokens": 8000
})

# æ³¨å†Œå¤–éƒ¨APIæœåŠ¡
model_manager.register_openai_model("azure_gpt4", {
    "model": "gpt-4",
    "api_key": os.getenv("AZURE_API_KEY"),
    "base_url": "https://your-resource.openai.azure.com/",
    "temperature": 0.2
})
```

### 5.2 å¤šæ¨¡å‹ç­–ç•¥é€‰æ‹©

æ ¹æ®ä¸åŒçš„ä»»åŠ¡ç±»å‹é€‰æ‹©æœ€é€‚åˆçš„æ¨¡å‹ï¼š

```python
def get_appropriate_model(task_type: str, complexity: str = "medium"):
    """æ ¹æ®ä»»åŠ¡ç±»å‹å’Œå¤æ‚åº¦é€‰æ‹©åˆé€‚çš„æ¨¡å‹"""
    
    if task_type == "code_analysis":
        if complexity == "high":
            return model_manager.get_model("company_gpt4")
        else:
            return model_manager.get_model("azure_gpt4")
    
    elif task_type == "creative_writing":
        # åˆ›æ„å†™ä½œä½¿ç”¨æ›´é«˜çš„æ¸©åº¦
        model = model_manager.get_model("company_gpt4")
        model.temperature = 0.8
        return model
    
    elif task_type == "data_analysis":
        # æ•°æ®åˆ†æéœ€è¦ç²¾ç¡®æ€§
        model = model_manager.get_model("company_gpt4")
        model.temperature = 0.0
        return model
    
    else:
        # é€šç”¨ä»»åŠ¡ä½¿ç”¨é»˜è®¤é…ç½®
        return model_manager.get_model("azure_gpt4")

def smart_processing_node(state: AgentState) -> AgentState:
    """æ™ºèƒ½å¤„ç†èŠ‚ç‚¹ï¼Œæ ¹æ®ä»»åŠ¡é€‰æ‹©æ¨¡å‹"""
    task_type = state.get("task_type", "general")
    complexity = state.get("complexity", "medium")
    
    llm = get_appropriate_model(task_type, complexity)
    
    # æ„å»ºæç¤ºè¯
    prompt = build_prompt(state, task_type)
    
    # è°ƒç”¨æ¨¡å‹
    response = llm.invoke(prompt)
    
    return {
        **state,
        "result": response.content,
        "model_used": llm.model_name
    }
```

### 5.3 æ¨¡å‹æ€§èƒ½ç›‘æ§

åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œç›‘æ§æ¨¡å‹æ€§èƒ½æ˜¯è‡³å…³é‡è¦çš„ï¼š

```python
import time
from typing import Dict, Any

class ModelMonitor:
    """æ¨¡å‹æ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.stats = {}
    
    def track_request(self, model_name: str, start_time: float, 
                     end_time: float, token_count: int, success: bool):
        """è·Ÿè¸ªæ¨¡å‹è¯·æ±‚æ€§èƒ½"""
        if model_name not in self.stats:
            self.stats[model_name] = {
                "total_requests": 0,
                "successful_requests": 0,
                "total_latency": 0,
                "total_tokens": 0,
                "avg_latency": 0,
                "success_rate": 0
            }
        
        stats = self.stats[model_name]
        stats["total_requests"] += 1
        
        if success:
            stats["successful_requests"] += 1
            latency = end_time - start_time
            stats["total_latency"] += latency
            stats["total_tokens"] += token_count
            
            # æ›´æ–°å¹³å‡å€¼
            stats["avg_latency"] = stats["total_latency"] / stats["successful_requests"]
        
        stats["success_rate"] = stats["successful_requests"] / stats["total_requests"]

# åˆ›å»ºç›‘æ§å™¨å®ä¾‹
monitor = ModelMonitor()

def monitored_model_call(model, prompt, model_name: str):
    """ç›‘æ§æ¨¡å‹è°ƒç”¨çš„åŒ…è£…å‡½æ•°"""
    start_time = time.time()
    
    try:
        response = model.invoke(prompt)
        end_time = time.time()
        
        # ä¼°ç®—tokenæ•°é‡ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        token_count = len(prompt) // 4 + len(response.content) // 4
        
        monitor.track_request(model_name, start_time, end_time, token_count, True)
        return response
        
    except Exception as e:
        end_time = time.time()
        monitor.track_request(model_name, start_time, end_time, 0, False)
        raise e
```

### 5.4 æ¨¡å‹å›é€€ç­–ç•¥

å½“ä¸»è¦æ¨¡å‹ä¸å¯ç”¨æ—¶ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ¨¡å‹ï¼š

```python
def resilient_model_call(prompt: str, task_type: str) -> str:
    """å…·æœ‰å›é€€æœºåˆ¶çš„æ¨¡å‹è°ƒç”¨"""
    
    # å®šä¹‰æ¨¡å‹ä¼˜å…ˆçº§
    model_priority = [
        ("company_gpt4", "ä¸»è¦æ¨¡å‹"),
        ("azure_gpt4", "Azureå¤‡ä»½"),
        ("public_gpt35", "å…¬å¼€APIå¤‡ä»½")
    ]
    
    for model_name, description in model_priority:
        try:
            model = model_manager.get_model(model_name)
            if model is None:
                continue
                
            response = monitored_model_call(model, prompt, model_name)
            print(f"âœ… ä½¿ç”¨ {description} æˆåŠŸ")
            return response.content
            
        except Exception as e:
            print(f"âŒ {description} å¤±è´¥: {e}")
            continue
    
    raise Exception("æ‰€æœ‰æ¨¡å‹éƒ½ä¸å¯ç”¨")
```

## å…­ã€å·¥å…·é›†æˆï¼šæ‰©å±•æ™ºèƒ½ä½“çš„èƒ½åŠ›è¾¹ç•Œ

### 6.1 å·¥å…·è°ƒç”¨çš„åŸºç¡€

çœŸæ­£å¼ºå¤§çš„æ™ºèƒ½ä½“ä¸ä»…èƒ½æ€è€ƒï¼Œè¿˜èƒ½è¡ŒåŠ¨ã€‚é€šè¿‡å·¥å…·é›†æˆï¼ŒAIå¯ä»¥è°ƒç”¨å¤–éƒ¨APIã€æ‰§è¡Œä»£ç ã€è®¿é—®æ•°æ®åº“ç­‰ï¼Œå°†è™šæ‹ŸåŠ©æ‰‹è½¬å˜ä¸ºå®ç”¨çš„æ‰§è¡Œè€…ã€‚

```python
from langchain_core.tools import tool
from typing import Annotated
import json

@tool
def search_database(query: str) -> str:
    """æœç´¢å…¬å¸æ•°æ®åº“ä¸­çš„ä¿¡æ¯
    
    Args:
        query: æœç´¢å…³é”®è¯æˆ–SQLæŸ¥è¯¢è¯­å¥
    
    Returns:
        JSONæ ¼å¼çš„æœç´¢ç»“æœ
    """
    # å®é™…çš„æ•°æ®åº“æŸ¥è¯¢é€»è¾‘
    results = execute_database_query(query)
    return json.dumps(results, ensure_ascii=False)

@tool  
def send_email(recipient: str, subject: str, body: str) -> str:
    """å‘é€é‚®ä»¶é€šçŸ¥
    
    Args:
        recipient: æ”¶ä»¶äººé‚®ç®±åœ°å€
        subject: é‚®ä»¶ä¸»é¢˜
        body: é‚®ä»¶æ­£æ–‡å†…å®¹
    
    Returns:
        å‘é€çŠ¶æ€ä¿¡æ¯
    """
    try:
        email_service.send(recipient, subject, body)
        return f"âœ… é‚®ä»¶å·²æˆåŠŸå‘é€è‡³ {recipient}"
    except Exception as e:
        return f"âŒ é‚®ä»¶å‘é€å¤±è´¥: {str(e)}"

@tool
def get_weather(location: str) -> str:
    """è·å–æŒ‡å®šåœ°ç‚¹çš„å¤©æ°”ä¿¡æ¯
    
    Args:
        location: åœ°ç‚¹åç§°ï¼ˆå¦‚ï¼šåŒ—äº¬ã€ä¸Šæµ·ï¼‰
    
    Returns:
        å¤©æ°”ä¿¡æ¯çš„JSONå­—ç¬¦ä¸²
    """
    weather_data = weather_api.get_current_weather(location)
    return json.dumps(weather_data, ensure_ascii=False)
```

### 6.2 å·¥å…·è°ƒç”¨èŠ‚ç‚¹çš„å®ç°

åœ¨LangGraphä¸­ï¼Œå·¥å…·è°ƒç”¨é€šå¸¸åœ¨ä¸“é—¨çš„èŠ‚ç‚¹ä¸­å¤„ç†ï¼š

```python
from langgraph.prebuilt import ToolNode
from langchain_core.messages import ToolMessage

def create_tool_calling_agent():
    """åˆ›å»ºæ”¯æŒå·¥å…·è°ƒç”¨çš„æ™ºèƒ½ä½“"""
    
    # å®šä¹‰æ‰€æœ‰å¯ç”¨å·¥å…·
    tools = [search_database, send_email, get_weather]
    
    # åˆ›å»ºç»‘å®šå·¥å…·çš„æ¨¡å‹
    model_with_tools = get_llm().bind_tools(tools)
    
    def call_model(state: MessagesState):
        """æ¨¡å‹è°ƒç”¨èŠ‚ç‚¹"""
        messages = state["messages"]
        response = model_with_tools.invoke(messages)
        return {"messages": [response]}
    
    def should_continue(state: MessagesState) -> str:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·"""
        messages = state["messages"]
        last_message = messages[-1]
        
        # å¦‚æœæœ€åä¸€æ¡æ¶ˆæ¯åŒ…å«å·¥å…·è°ƒç”¨ï¼Œåˆ™æ‰§è¡Œå·¥å…·
        if last_message.tool_calls:
            return "tools"
        # å¦åˆ™ç»“æŸ
        return "end"
    
    # æ„å»ºå›¾
    workflow = StateGraph(MessagesState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", ToolNode(tools))
    
    # è®¾ç½®è¾¹
    workflow.set_entry_point("agent")
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {"tools": "tools", "end": END}
    )
    workflow.add_edge("tools", "agent")
    
    return workflow.compile()
```

### 6.3 é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶

åœ¨å®é™…åº”ç”¨ä¸­ï¼Œå·¥å…·è°ƒç”¨å¯èƒ½ä¼šå¤±è´¥ï¼Œéœ€è¦å»ºç«‹å¥å£®çš„é”™è¯¯å¤„ç†æœºåˆ¶ï¼š

```python
@tool
def robust_api_call(endpoint: str, params: dict) -> str:
    """å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨å·¥å…·
    
    Args:
        endpoint: APIç«¯ç‚¹URL
        params: è¯·æ±‚å‚æ•°
    
    Returns:
        APIå“åº”ç»“æœ
    """
    max_retries = 3
    base_delay = 1
    
    for attempt in range(max_retries):
        try:
            # æ¨¡æ‹ŸAPIè°ƒç”¨
            print(f"å°è¯•ç¬¬ {attempt + 1} æ¬¡APIè°ƒç”¨: {endpoint}")
            
            # æ¨¡æ‹Ÿéšæœºå¤±è´¥ï¼ˆ70%æˆåŠŸç‡ï¼‰
            import random
            if random.random() < 0.7:  # 70%æˆåŠŸç‡
                response_data = {
                    "status": "success",
                    "data": f"APIè°ƒç”¨æˆåŠŸï¼Œå‚æ•°: {params}",
                    "endpoint": endpoint
                }
                
                return json.dumps({
                    "success": True,
                    "data": response_data,
                    "attempt": attempt + 1
                }, ensure_ascii=False)
            else:
                raise Exception("æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯")
                
        except Exception as e:
            if attempt == max_retries - 1:
                return json.dumps({
                    "success": False,
                    "error": f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {str(e)}",
                    "attempt": attempt + 1
                }, ensure_ascii=False)
            
            # æŒ‡æ•°é€€é¿
            delay = base_delay * (2 ** attempt)
            print(f"ç¬¬ {attempt + 1} æ¬¡å°è¯•å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯•...")
            time.sleep(delay)
    
    return json.dumps({"success": False, "error": "æœªçŸ¥é”™è¯¯"}, ensure_ascii=False)
```

### 6.4 å·¥å…·æƒé™å’Œå®‰å…¨æ§åˆ¶

åœ¨ä¼ä¸šç¯å¢ƒä¸­ï¼Œå·¥å…·çš„ä½¿ç”¨éœ€è¦é€‚å½“çš„æƒé™æ§åˆ¶ï¼š

```python
from functools import wraps
from typing import List

def require_permissions(required_permissions: List[str]):
    """è£…é¥°å™¨ï¼šè¦æ±‚ç‰¹å®šæƒé™æ‰èƒ½ä½¿ç”¨å·¥å…·"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            # ä»ä¸Šä¸‹æ–‡è·å–ç”¨æˆ·æƒé™ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
            user_permissions = get_current_user_permissions()
            
            for permission in required_permissions:
                if permission not in user_permissions:
                    return f"âŒ æƒé™ä¸è¶³ï¼šéœ€è¦ {permission} æƒé™"
            
            return func(*args, **kwargs)
        return wrapper
    return decorator

@tool
@require_permissions(["database.read"])
def secure_database_search(query: str) -> str:
    """å—æƒé™ä¿æŠ¤çš„æ•°æ®åº“æœç´¢"""
    return search_database(query)

@tool  
@require_permissions(["email.send"])
def secure_send_email(recipient: str, subject: str, body: str) -> str:
    """å—æƒé™ä¿æŠ¤çš„é‚®ä»¶å‘é€"""
    return send_email(recipient, subject, body)
```

### 6.5 å·¥å…·ç¼–æ’ç­–ç•¥

åœ¨å¤æ‚åœºæ™¯ä¸­ï¼Œæ™ºèƒ½ä½“éœ€è¦åè°ƒå¤šä¸ªå·¥å…·çš„ä½¿ç”¨ã€‚ä»¥ä¸‹æ˜¯å‡ ç§å¸¸è§çš„å·¥å…·ç¼–æ’ç­–ç•¥ï¼š

#### 6.5.1 é¡ºåºæ‰§è¡Œç­–ç•¥

```python
def sequential_tool_workflow(state: AgentState) -> AgentState:
    """é¡ºåºæ‰§è¡Œå¤šä¸ªå·¥å…·çš„å·¥ä½œæµ"""
    
    # æ­¥éª¤1ï¼šæœç´¢ç›¸å…³ä¿¡æ¯
    search_result = search_database(state["query"])
    
    # æ­¥éª¤2ï¼šåŸºäºæœç´¢ç»“æœè·å–è¯¦ç»†ä¿¡æ¯
    if "weather" in search_result:
        weather_info = get_weather(state["location"])
        
    # æ­¥éª¤3ï¼šå‘é€æ±‡æ€»é‚®ä»¶
    summary = f"æœç´¢ç»“æœï¼š{search_result}\nå¤©æ°”ä¿¡æ¯ï¼š{weather_info}"
    send_email(state["recipient"], "ä¿¡æ¯æ±‡æ€»", summary)
    
    return {
        **state,
        "result": "ä»»åŠ¡å®Œæˆ",
        "steps_completed": ["æœç´¢", "å¤©æ°”æŸ¥è¯¢", "é‚®ä»¶å‘é€"]
    }
```

#### 6.5.2 å¹¶è¡Œæ‰§è¡Œç­–ç•¥

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

async def parallel_tool_workflow(state: AgentState) -> AgentState:
    """å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·çš„å·¥ä½œæµ"""
    
    async def async_search():
        return search_database(state["query"])
    
    async def async_weather():
        return get_weather(state["location"])
    
    async def async_user_profile():
        return get_user_profile(state["user_id"])
    
    # å¹¶è¡Œæ‰§è¡Œå¤šä¸ªå·¥å…·
    results = await asyncio.gather(
        async_search(),
        async_weather(),
        async_user_profile(),
        return_exceptions=True
    )
    
    # å¤„ç†ç»“æœ
    search_result, weather_result, profile_result = results
    
    return {
        **state,
        "search_result": search_result,
        "weather_result": weather_result,
        "profile_result": profile_result,
        "execution_time": "å¹¶è¡Œæ‰§è¡Œå®Œæˆ"
    }
```

#### 6.5.3 æ¡ä»¶åˆ†æ”¯ç­–ç•¥

```python
def conditional_tool_workflow(state: AgentState) -> AgentState:
    """åŸºäºæ¡ä»¶é€‰æ‹©ä¸åŒçš„å·¥å…·æ‰§è¡Œè·¯å¾„"""
    
    request_type = classify_request(state["user_input"])
    
    if request_type == "information_query":
        # ä¿¡æ¯æŸ¥è¯¢è·¯å¾„
        result = search_database(state["query"])
        
    elif request_type == "weather_request":
        # å¤©æ°”æŸ¥è¯¢è·¯å¾„
        result = get_weather(state["location"])
        
    elif request_type == "email_task":
        # é‚®ä»¶ä»»åŠ¡è·¯å¾„
        result = send_email(
            state["recipient"], 
            state["subject"], 
            state["body"]
        )
        
    else:
        # é»˜è®¤è·¯å¾„
        result = "æŠ±æ­‰ï¼Œæˆ‘ä¸ç¡®å®šå¦‚ä½•å¤„ç†è¿™ä¸ªè¯·æ±‚"
    
    return {
        **state,
        "result": result,
        "request_type": request_type
    }
```

#### 6.5.4 å·¥å…·é“¾ç­–ç•¥

```python
class ToolChain:
    """å·¥å…·é“¾ï¼šå°†å¤šä¸ªå·¥å…·ç»„åˆæˆä¸€ä¸ªå¤æ‚çš„å¤„ç†ç®¡é“"""
    
    def __init__(self, tools: List):
        self.tools = tools
        self.results = []
    
    def execute(self, initial_input: str) -> str:
        """æ‰§è¡Œå·¥å…·é“¾"""
        current_input = initial_input
        
        for i, tool in enumerate(self.tools):
            try:
                result = tool.invoke(current_input)
                self.results.append({
                    "step": i + 1,
                    "tool": tool.name,
                    "input": current_input,
                    "output": result
                })
                
                # å°†å½“å‰ç»“æœä½œä¸ºä¸‹ä¸€ä¸ªå·¥å…·çš„è¾“å…¥
                current_input = result
                
            except Exception as e:
                error_msg = f"å·¥å…·é“¾åœ¨ç¬¬{i+1}æ­¥å¤±è´¥: {str(e)}"
                self.results.append({
                    "step": i + 1,
                    "tool": tool.name,
                    "error": error_msg
                })
                return error_msg
        
        return current_input

# ä½¿ç”¨ç¤ºä¾‹
def create_research_chain():
    """åˆ›å»ºç ”ç©¶å·¥å…·é“¾"""
    return ToolChain([
        search_database,      # 1. æœç´¢åŸºç¡€ä¿¡æ¯
        get_weather,         # 2. è·å–ç›¸å…³å¤©æ°”ä¿¡æ¯  
        send_email          # 3. å‘é€ç ”ç©¶ç»“æœ
    ])
```



## ä¸ƒã€äººæœºäº¤äº’ï¼šåœ¨å…³é”®æ—¶åˆ»å¼•å…¥äººç±»æ™ºæ…§

äººæœºåä½œæ˜¯ä¼ä¸šçº§AIåº”ç”¨çš„æ ¸å¿ƒç‰¹å¾ã€‚LangGraphæä¾›äº†å¼ºå¤§çš„äººæœºäº¤äº’æœºåˆ¶ï¼Œè®©æ™ºèƒ½ä½“èƒ½å¤Ÿåœ¨å…³é”®æ—¶åˆ»å¯»æ±‚äººç±»çš„åˆ¤æ–­å’ŒæŒ‡å¯¼ã€‚

### 7.1 ä¸­æ–­æœºåˆ¶ï¼šæ™ºèƒ½ä½“çš„"è¯·ç¤º"èƒ½åŠ›

å½“æ™ºèƒ½ä½“é‡åˆ°éœ€è¦äººç±»åˆ¤æ–­çš„æƒ…å†µæ—¶ï¼Œå¯ä»¥ä¸»åŠ¨æš‚åœæ‰§è¡Œï¼Œç­‰å¾…äººå·¥å¹²é¢„ã€‚è¿™ç§æœºåˆ¶åœ¨å¤„ç†æ•æ„Ÿæ“ä½œã€é‡è¦å†³ç­–æˆ–ä¸ç¡®å®šæƒ…å†µæ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚

#### 7.1.1 ç¼–è¯‘æ—¶è®¾ç½®ä¸­æ–­ç‚¹

```python
# åœ¨ç‰¹å®šèŠ‚ç‚¹å‰ä¸­æ–­
app = workflow.compile(
    checkpointer=checkpointer,
    interrupt_before=["sensitive_operation", "final_decision"]
)

# æ‰§è¡Œåˆ°ä¸­æ–­ç‚¹
config = {"configurable": {"thread_id": "user_session_123"}}
result = app.invoke({
    "messages": [{"role": "user", "content": "è¯·å¸®æˆ‘åˆ é™¤æ‰€æœ‰å®¢æˆ·æ•°æ®"}]
}, config)

print("æ™ºèƒ½ä½“å·²æš‚åœï¼Œç­‰å¾…äººå·¥ç¡®è®¤...")
```

#### 7.1.2 åŠ¨æ€ä¸­æ–­æ§åˆ¶

```python
from langgraph.types import interrupt

def sensitive_operation_node(state: MessagesState) -> MessagesState:
    """æ•æ„Ÿæ“ä½œèŠ‚ç‚¹ï¼ŒåŠ¨æ€å†³å®šæ˜¯å¦éœ€è¦äººå·¥ç¡®è®¤"""
    
    operation_type = classify_operation(state["messages"][-1].content)
    risk_level = assess_risk(operation_type)
    
    if risk_level == "high":
        # åŠ¨æ€è§¦å‘ä¸­æ–­
        interrupt("éœ€è¦äººå·¥ç¡®è®¤é«˜é£é™©æ“ä½œ")
    
    # ç»§ç»­æ‰§è¡Œ
    return execute_operation(state)
```

#### 7.1.3 ä¸­æ–­åçš„å¤„ç†æµç¨‹

```python
def handle_human_in_the_loop():
    """å¤„ç†äººæœºäº¤äº’çš„å®Œæ•´æµç¨‹"""
    
    # 1. æ‰§è¡Œåˆ°ä¸­æ–­ç‚¹
    try:
        result = app.invoke(initial_state, config)
        print("å·¥ä½œæµæ­£å¸¸å®Œæˆ")
        return result
        
    except GraphInterrupt as interrupt_info:
        print(f"å·¥ä½œæµåœ¨èŠ‚ç‚¹ '{interrupt_info.node}' å¤„ä¸­æ–­")
        print(f"ä¸­æ–­åŸå› : {interrupt_info.reason}")
        
        # 2. è·å–å½“å‰çŠ¶æ€
        current_state = app.get_state(config)
        print(f"å½“å‰çŠ¶æ€: {current_state.values}")
        
        # 3. ç­‰å¾…äººå·¥å†³ç­–
        human_decision = get_human_approval(current_state)
        
        if human_decision["approved"]:
            # 4. æ·»åŠ äººå·¥åé¦ˆåˆ°çŠ¶æ€
            updated_state = {
                **current_state.values,
                "human_feedback": human_decision["feedback"],
                "approved": True
            }
            
            # 5. æ›´æ–°çŠ¶æ€å¹¶ç»§ç»­æ‰§è¡Œ
            app.update_state(config, updated_state)
            final_result = app.invoke(None, config)
            
            return final_result
        else:
            print("æ“ä½œè¢«äººå·¥æ‹’ç»")
            return {"status": "rejected", "reason": human_decision["reason"]}
```

### 7.2 å¤šç§ä¸­æ–­ç­–ç•¥

LangGraphæ”¯æŒå¤šç§ä¸­æ–­ç­–ç•¥ï¼Œä»¥é€‚åº”ä¸åŒçš„ä¸šåŠ¡éœ€æ±‚ï¼š

#### 7.2.1 åŸºäºå†…å®¹çš„ä¸­æ–­

```python
def content_based_interrupt(state: MessagesState) -> MessagesState:
    """åŸºäºæ¶ˆæ¯å†…å®¹å†³å®šæ˜¯å¦ä¸­æ–­"""
    last_message = state["messages"][-1].content.lower()
    
    # æ£€æµ‹æ•æ„Ÿå…³é”®è¯
    sensitive_keywords = ["åˆ é™¤", "åˆ åº“", "é‡ç½®å¯†ç ", "è½¬è´¦"]
    
    for keyword in sensitive_keywords:
        if keyword in last_message:
            interrupt(f"æ£€æµ‹åˆ°æ•æ„Ÿæ“ä½œå…³é”®è¯: {keyword}")
    
    return state
```

#### 7.2.2 åŸºäºç”¨æˆ·æƒé™çš„ä¸­æ–­

```python
def permission_based_interrupt(state: MessagesState, config) -> MessagesState:
    """åŸºäºç”¨æˆ·æƒé™å†³å®šæ˜¯å¦éœ€è¦é¢å¤–ç¡®è®¤"""
    user_role = config["configurable"].get("user_role", "user")
    operation = extract_operation(state["messages"][-1].content)
    
    # æ™®é€šç”¨æˆ·æ‰§è¡Œç®¡ç†å‘˜æ“ä½œéœ€è¦å®¡æ‰¹
    if user_role == "user" and operation in ["admin_operations"]:
        interrupt("æ™®é€šç”¨æˆ·æ‰§è¡Œç®¡ç†å‘˜æ“ä½œï¼Œéœ€è¦ç®¡ç†å‘˜å®¡æ‰¹")
    
    return state
```

#### 7.2.3 åŸºäºç½®ä¿¡åº¦çš„ä¸­æ–­

```python
def confidence_based_interrupt(state: MessagesState) -> MessagesState:
    """åŸºäºAIç½®ä¿¡åº¦å†³å®šæ˜¯å¦éœ€è¦äººå·¥ç¡®è®¤"""
    
    # è¯„ä¼°AIå¯¹å½“å‰ä»»åŠ¡çš„ç½®ä¿¡åº¦
    confidence = assess_confidence(state)
    
    if confidence < 0.7:  # ç½®ä¿¡åº¦ä½äº70%
        interrupt(f"AIç½®ä¿¡åº¦è¾ƒä½({confidence:.2f})ï¼Œå»ºè®®äººå·¥å®¡æ ¸")
    
    return state
```

### 7.3 äººå·¥åé¦ˆçš„é›†æˆ

äººå·¥åé¦ˆä¸ä»…ç”¨äºå®¡æ‰¹ï¼Œè¿˜èƒ½å¸®åŠ©æ™ºèƒ½ä½“å­¦ä¹ å’Œæ”¹è¿›ï¼š

```python
def incorporate_human_feedback(state: MessagesState) -> MessagesState:
    """æ•´åˆäººå·¥åé¦ˆï¼Œæ”¹è¿›æ™ºèƒ½ä½“è¡Œä¸º"""
    
    feedback = state.get("human_feedback", {})
    
    if feedback:
        # è®°å½•åé¦ˆç”¨äºåç»­å­¦ä¹ 
        log_feedback(feedback, state["context"])
        
        # æ ¹æ®åé¦ˆè°ƒæ•´å½“å‰å¤„ç†ç­–ç•¥
        if feedback.get("suggestion"):
            adjusted_approach = modify_approach(
                state["current_approach"], 
                feedback["suggestion"]
            )
            
            return {
                **state,
                "current_approach": adjusted_approach,
                "feedback_incorporated": True
            }
    
    return state
```

### 7.4 å®æ—¶åä½œç•Œé¢

ä¸ºäº†æé«˜äººæœºåä½œçš„æ•ˆç‡ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºå®æ—¶åä½œç•Œé¢ï¼š

```python
class HumanCollaborationInterface:
    """äººæœºåä½œç•Œé¢"""
    
    def __init__(self):
        self.pending_approvals = {}
        self.notification_handlers = []
    
    def request_approval(self, session_id: str, context: dict):
        """è¯·æ±‚äººå·¥å®¡æ‰¹"""
        approval_request = {
            "session_id": session_id,
            "timestamp": datetime.now(),
            "context": context,
            "status": "pending"
        }
        
        self.pending_approvals[session_id] = approval_request
        
        # é€šçŸ¥ç›¸å…³äººå‘˜
        self.notify_reviewers(approval_request)
        
        return approval_request
    
    def provide_approval(self, session_id: str, decision: dict):
        """æä¾›å®¡æ‰¹å†³ç­–"""
        if session_id in self.pending_approvals:
            self.pending_approvals[session_id].update({
                "decision": decision,
                "status": "completed",
                "completed_at": datetime.now()
            })
            
            # é€šçŸ¥æ™ºèƒ½ä½“å¯ä»¥ç»§ç»­
            self.notify_agent_continuation(session_id, decision)
    
    def notify_reviewers(self, request: dict):
        """é€šçŸ¥å®¡æ ¸äººå‘˜"""
        # å¯ä»¥é€šè¿‡é‚®ä»¶ã€å³æ—¶æ¶ˆæ¯ã€æ¨é€é€šçŸ¥ç­‰æ–¹å¼
        for handler in self.notification_handlers:
            handler.send_notification(request)

# ä½¿ç”¨ç¤ºä¾‹
collaboration_interface = HumanCollaborationInterface()

def smart_interrupt_node(state: MessagesState, config) -> MessagesState:
    """æ™ºèƒ½ä¸­æ–­èŠ‚ç‚¹"""
    session_id = config["configurable"]["thread_id"]
    
    # è¯„ä¼°æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
    if requires_human_review(state):
        # è¯·æ±‚äººå·¥å®¡æ‰¹
        approval_request = collaboration_interface.request_approval(
            session_id, 
            {
                "operation": extract_operation(state),
                "risk_level": assess_risk_level(state),
                "context": state["messages"][-3:]  # æœ€è¿‘3æ¡æ¶ˆæ¯ä½œä¸ºä¸Šä¸‹æ–‡
            }
        )
        
        # è§¦å‘ä¸­æ–­ï¼Œç­‰å¾…å®¡æ‰¹
        interrupt(f"ç­‰å¾…å®¡æ‰¹ï¼Œè¯·æ±‚ID: {approval_request['session_id']}")
    
    return state
```

### 7.5 å®¡è®¡å’Œåˆè§„

åœ¨ä¼ä¸šç¯å¢ƒä¸­ï¼Œäººæœºäº¤äº’çš„è®°å½•å¯¹äºå®¡è®¡å’Œåˆè§„è‡³å…³é‡è¦ï¼š

```python
class InteractionAuditor:
    """äººæœºäº¤äº’å®¡è®¡å™¨"""
    
    def __init__(self, audit_db):
        self.audit_db = audit_db
    
    def log_interrupt(self, session_id: str, node_name: str, reason: str):
        """è®°å½•ä¸­æ–­äº‹ä»¶"""
        audit_record = {
            "event_type": "interrupt",
            "session_id": session_id,
            "node_name": node_name,
            "reason": reason,
            "timestamp": datetime.now(),
            "user_context": get_user_context(session_id)
        }
        
        self.audit_db.insert(audit_record)
    
    def log_human_decision(self, session_id: str, decision: dict):
        """è®°å½•äººå·¥å†³ç­–"""
        audit_record = {
            "event_type": "human_decision",
            "session_id": session_id,
            "decision": decision,
            "timestamp": datetime.now(),
            "reviewer": decision.get("reviewer_id"),
            "justification": decision.get("justification")
        }
        
        self.audit_db.insert(audit_record)
    
    def generate_compliance_report(self, date_range: tuple):
        """ç”Ÿæˆåˆè§„æŠ¥å‘Š"""
        interactions = self.audit_db.query_date_range(date_range)
        
        report = {
            "total_interrupts": len([i for i in interactions if i["event_type"] == "interrupt"]),
            "approval_rate": self.calculate_approval_rate(interactions),
            "avg_response_time": self.calculate_avg_response_time(interactions),
            "compliance_violations": self.detect_violations(interactions)
        }
        
        return report
```


## å…«ã€MCPé›†æˆï¼šè¿æ¥å¤–éƒ¨ä¸–ç•Œ

### 8.1 ä»€ä¹ˆæ˜¯MCPï¼Ÿ

Model Context Protocol (MCP) æ˜¯ä¸€ç§å¼€æ”¾æ ‡å‡†åè®®ï¼Œä¸“é—¨è®¾è®¡ç”¨äºåœ¨ AI æ¨¡å‹å’Œå¤–éƒ¨æ•°æ®æºã€å·¥å…·ä¹‹é—´å»ºç«‹å®‰å…¨ã€æ ‡å‡†åŒ–çš„è¿æ¥ã€‚MCPçš„æ ¸å¿ƒä»·å€¼åœ¨äºä¸ºAIåº”ç”¨æä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„æ¥å£æ¥è®¿é—®å„ç§å¤–éƒ¨èµ„æºï¼Œè€Œæ— éœ€ä¸ºæ¯ä¸ªç³»ç»Ÿå•ç‹¬å¼€å‘é›†æˆä»£ç ã€‚

MCPçš„ä¸»è¦ä¼˜åŠ¿ï¼š

- **æ ‡å‡†åŒ–**ï¼šç»Ÿä¸€çš„åè®®è§„èŒƒï¼Œé™ä½é›†æˆå¤æ‚åº¦
- **å®‰å…¨æ€§**ï¼šå†…ç½®æƒé™æ§åˆ¶å’Œè®¿é—®é™åˆ¶æœºåˆ¶
- **å¯æ‰©å±•æ€§**ï¼šæ”¯æŒå„ç§ç±»å‹çš„å¤–éƒ¨èµ„æºå’Œå·¥å…·
- **äº’æ“ä½œæ€§**ï¼šä¸åŒä¾›åº”å•†çš„å·¥å…·å¯ä»¥æ— ç¼åä½œ

### 8.2 LangGraphä¸­çš„MCPé›†æˆ

LangGraphé€šè¿‡`langchain-mcp-adapters`æä¾›å¯¹MCPçš„æ”¯æŒï¼Œè®©æ™ºèƒ½ä½“èƒ½å¤Ÿè½»æ¾è®¿é—®é€šè¿‡MCPæš´éœ²çš„å¤–éƒ¨æœåŠ¡ã€‚

#### 8.2.1 MCPå®¢æˆ·ç«¯é…ç½®

```python
from langchain_mcp_adapters.client import MultiServerMCPClient
import asyncio

class MCPClientManager:
    """MCPå®¢æˆ·ç«¯ç®¡ç†å™¨"""
    
    def __init__(self):
        self.client = None
        self.available_tools = []
        self.server_config = {}
    
    async def connect_to_server(self, server_url: str) -> bool:
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨
        
        Args:
            server_url: MCPæœåŠ¡å™¨çš„SSE URL
            
        Returns:
            bool: è¿æ¥æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆ›å»ºæœåŠ¡å™¨é…ç½®
            self.server_config = {
                "mcp_server": {
                    "transport": "sse",
                    "url": server_url
                }
            }
            
            print(f"ğŸ”— æ­£åœ¨è¿æ¥åˆ°MCPæœåŠ¡å™¨: {server_url}")
            
            # åˆ›å»ºMCPå®¢æˆ·ç«¯
            self.client = MultiServerMCPClient(self.server_config)
            
            # è·å–å¯ç”¨å·¥å…·
            self.available_tools = await self.client.get_tools()
            
            print(f"âœ… æˆåŠŸè¿æ¥åˆ°MCPæœåŠ¡å™¨")
            print(f"ğŸ› ï¸ å‘ç° {len(self.available_tools)} ä¸ªå¯ç”¨å·¥å…·")
            
            # æ˜¾ç¤ºå·¥å…·ä¿¡æ¯
            for tool in self.available_tools:
                print(f"  â€¢ {tool.name}: {tool.description}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¿æ¥MCPæœåŠ¡å™¨å¤±è´¥: {e}")
            return False
    
    def get_tools(self):
        """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨"""
        return self.available_tools if self.available_tools else []
    
    async def call_tool(self, tool_name: str, arguments: dict):
        """è°ƒç”¨å·¥å…·"""
        if not self.client:
            raise Exception("MCPå®¢æˆ·ç«¯æœªè¿æ¥")
        
        try:
            result = await self.client.call_tool(tool_name, arguments)
            return result
        except Exception as e:
            raise Exception(f"å·¥å…·è°ƒç”¨å¤±è´¥: {e}")

# ä½¿ç”¨ç¤ºä¾‹
async def setup_mcp_connection():
    """è®¾ç½®MCPè¿æ¥"""
    mcp_manager = MCPClientManager()
    
    # è¿æ¥åˆ°MCPæœåŠ¡å™¨ï¼ˆä½¿ç”¨SSEä¼ è¾“ï¼‰
    server_url = "http://localhost:8000/mcp/sse"
    success = await mcp_manager.connect_to_server(server_url)
    
    if success:
        return mcp_manager
    else:
        print("âš ï¸ æ— æ³•è¿æ¥åˆ°MCPæœåŠ¡å™¨")
        return None
```

#### 8.2.2 MCPå·¥å…·ä¸LLMæ™ºèƒ½ä½“é›†æˆ

```python
from langgraph.prebuilt import ToolNode
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict, Annotated
from typing import List
from langchain_core.messages import BaseMessage, SystemMessage
from langgraph.graph.message import add_messages

async def create_mcp_integrated_agent(mcp_manager):
    """åˆ›å»ºé›†æˆMCPå·¥å…·çš„æ™ºèƒ½ä½“"""
    
    # è·å–MCPå·¥å…·
    mcp_tools = mcp_manager.get_tools()
    
    if not mcp_tools:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„MCPå·¥å…·")
        return None
    
    print(f"ğŸ› ï¸ å¯ç”¨çš„MCPå·¥å…·: {[tool.name for tool in mcp_tools]}")
    
    # åˆ›å»ºLLMå¹¶ç»‘å®šå·¥å…·
    llm = get_llm()
    llm_with_tools = llm.bind_tools(mcp_tools)
    
    # å®šä¹‰çŠ¶æ€
    class State(TypedDict):
        messages: Annotated[List[BaseMessage], add_messages]
    
    # å®šä¹‰æ™ºèƒ½ä½“èŠ‚ç‚¹
    def agent_node(state: State):
        """æ™ºèƒ½ä½“èŠ‚ç‚¹ - åˆ†æç”¨æˆ·è¯·æ±‚å¹¶å†³å®šæ˜¯å¦è°ƒç”¨å·¥å…·"""
        messages = state["messages"]
        
        # æ·»åŠ ç³»ç»Ÿæç¤º
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¿ç»´åŠ©æ‰‹ï¼Œå¯ä»¥é€šè¿‡MCPå·¥å…·è¿œç¨‹æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ã€‚

å½“ç”¨æˆ·è¯¢é—®ç³»ç»ŸçŠ¶æ€ã€æ‰§è¡Œå‘½ä»¤æˆ–æŸ¥çœ‹ä¿¡æ¯æ—¶ï¼Œè¯·ä½¿ç”¨available toolsæ¥å®Œæˆä»»åŠ¡ã€‚

å¯ç”¨å·¥å…·:
- remote_exec: åœ¨è¿œç¨‹è®¾å¤‡ä¸Šæ‰§è¡Œshellå‘½ä»¤
  å‚æ•°: machineId (è®¾å¤‡ID), script (è¦æ‰§è¡Œçš„shellå‘½ä»¤)

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚æ™ºèƒ½é€‰æ‹©å’Œè°ƒç”¨å·¥å…·ã€‚å¦‚æœç”¨æˆ·æä¾›äº†è®¾å¤‡IDï¼Œè¯·ä½¿ç”¨è¯¥IDï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤è®¾å¤‡IDã€‚
"""
        
        # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯åˆ—è¡¨
        full_messages = [SystemMessage(content=system_prompt)] + messages
        
        # è°ƒç”¨LLM
        response = llm_with_tools.invoke(full_messages)
        return {"messages": [response]}
    
    # å®šä¹‰å·¥å…·èŠ‚ç‚¹ - ä½¿ç”¨ToolNodeè‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨
    tool_node = ToolNode(mcp_tools)
    
    # å®šä¹‰è·¯ç”±å‡½æ•°
    def should_continue(state: State):
        """åˆ¤æ–­æ˜¯å¦éœ€è¦ç»§ç»­è°ƒç”¨å·¥å…·"""
        last_message = state["messages"][-1]
        
        # å¦‚æœLLMè¿”å›äº†å·¥å…·è°ƒç”¨ï¼Œåˆ™è·¯ç”±åˆ°å·¥å…·èŠ‚ç‚¹
        if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
            return "call_tool"
        return "end"
    
    # æ„å»ºå·¥ä½œæµå›¾
    workflow = StateGraph(State)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("agent", agent_node)
    workflow.add_node("call_tool", tool_node)
    
    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("agent")
    
    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "call_tool": "call_tool",
            "end": END
        }
    )
    
    # å·¥å…·è°ƒç”¨åè¿”å›æ™ºèƒ½ä½“
    workflow.add_edge("call_tool", "agent")
    
    # ç¼–è¯‘å›¾
    app = workflow.compile()
    
    return app

# ä½¿ç”¨ç¤ºä¾‹
async def test_mcp_agent():
    """æµ‹è¯•MCPé›†æˆçš„æ™ºèƒ½ä½“"""
    # è®¾ç½®MCPè¿æ¥
    mcp_manager = await setup_mcp_connection()
    if not mcp_manager:
        return
    
    # åˆ›å»ºæ™ºèƒ½ä½“
    agent = await create_mcp_integrated_agent(mcp_manager)
    if not agent:
        return
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "æŸ¥çœ‹è®¾å¤‡ 6fa31edaac8bee6cc75cd8ae1bc03930 çš„ç³»ç»Ÿè´Ÿè½½æƒ…å†µ",
        "åœ¨è®¾å¤‡ 6fa31edaac8bee6cc75cd8ae1bc03930 ä¸Šæ‰§è¡Œ df -h æŸ¥çœ‹ç£ç›˜ä½¿ç”¨",
        "æ£€æŸ¥è®¾å¤‡ 6fa31edaac8bee6cc75cd8ae1bc03930 çš„å†…å­˜ä½¿ç”¨æƒ…å†µ free -h"
    ]
    
    for query in test_queries:
        print(f"ğŸ¤– æ™ºèƒ½ä½“æµ‹è¯•: {query}")
        
        try:
            # è°ƒç”¨æ™ºèƒ½ä½“
            result = await agent.ainvoke({"messages": [{"role": "user", "content": query}]})
            
            # è·å–æœ€ç»ˆå›å¤
            final_message = result["messages"][-1]
            
            if hasattr(final_message, 'content') and final_message.content:
                print(f"âœ… æ™ºèƒ½ä½“å›å¤: {final_message.content[:300]}...")
            else:
                print(f"ğŸ“‹ å·¥å…·è°ƒç”¨ç»“æœ: {str(final_message)[:300]}...")
                
        except Exception as e:
            print(f"âŒ æ™ºèƒ½ä½“è°ƒç”¨å¤±è´¥: {str(e)}")
        
        print("=" * 60)
```

### 8.3 MCPå·¥å…·çš„åŠ¨æ€å‘ç°

MCPæ”¯æŒå·¥å…·çš„åŠ¨æ€å‘ç°ï¼Œè®©æ™ºèƒ½ä½“èƒ½å¤Ÿè‡ªåŠ¨äº†è§£å’Œä½¿ç”¨æ–°çš„å·¥å…·ï¼š

```python
async def discover_and_register_tools():
    """åŠ¨æ€å‘ç°å¹¶æ³¨å†ŒMCPå·¥å…·"""
    all_tools = []
    
    for server_name, client in mcp_manager.clients.items():
        try:
            # è·å–æœåŠ¡å™¨æä¾›çš„æ‰€æœ‰å·¥å…·
            tools = await client.list_tools()
            
            for tool in tools:
                # åˆ›å»ºLangGraphå·¥å…·åŒ…è£…å™¨
                langraph_tool = create_mcp_tool_wrapper(
                    server_name, 
                    tool["name"], 
                    tool["description"],
                    tool["inputSchema"]
                )
                
                all_tools.append(langraph_tool)
                
        except Exception as e:
            print(f"è·å– {server_name} å·¥å…·åˆ—è¡¨å¤±è´¥: {e}")
    
    return all_tools

def create_mcp_tool_wrapper(server_name: str, tool_name: str, 
                           description: str, input_schema: dict):
    """ä¸ºMCPå·¥å…·åˆ›å»ºLangGraphåŒ…è£…å™¨"""
    
    @tool
    async def mcp_tool_wrapper(**kwargs) -> str:
        f"""
        {description}
        
        æœåŠ¡å™¨: {server_name}
        å·¥å…·: {tool_name}
        """
        try:
            result = await mcp_manager.call_tool(server_name, tool_name, kwargs)
            return json.dumps(result, ensure_ascii=False)
        except Exception as e:
            return f"è°ƒç”¨å·¥å…·å¤±è´¥: {str(e)}"
    
    # è®¾ç½®å·¥å…·åç§°å’Œæè¿°
    mcp_tool_wrapper.name = f"{server_name}_{tool_name}"
    mcp_tool_wrapper.description = description
    
    return mcp_tool_wrapper
```

### 8.4 MCPèµ„æºè®¿é—®

é™¤äº†å·¥å…·è°ƒç”¨ï¼ŒMCPè¿˜æ”¯æŒè®¿é—®å„ç§èµ„æºï¼ˆå¦‚æ–‡ä»¶ã€æ•°æ®åº“è®°å½•ç­‰ï¼‰ï¼š

```python
async def access_mcp_resources(state: MessagesState) -> MessagesState:
    """è®¿é—®MCPèµ„æº"""
    
    user_query = state["messages"][-1].content
    
    # æ ¹æ®æŸ¥è¯¢ç±»å‹è®¿é—®ä¸åŒèµ„æº
    if "æ–‡æ¡£" in user_query:
        # è®¿é—®æ–‡æ¡£èµ„æº
        resources = await mcp_manager.clients["document_server"].list_resources()
        
        relevant_docs = []
        for resource in resources:
            if is_relevant_document(resource, user_query):
                content = await mcp_manager.clients["document_server"].read_resource(
                    resource["uri"]
                )
                relevant_docs.append(content)
        
        response = summarize_documents(relevant_docs)
        
    elif "æ•°æ®åº“" in user_query:
        # è®¿é—®æ•°æ®åº“èµ„æº
        query_result = await mcp_manager.clients["db_server"].query_resource(
            "database://company/analytics",
            extract_sql_query(user_query)
        )
        
        response = format_query_results(query_result)
    
    return {
        **state,
        "messages": state["messages"] + [{
            "role": "assistant", 
            "content": response
        }]
    }
```

### 8.5 MCPå®‰å…¨å’Œæƒé™ç®¡ç†

MCPæä¾›äº†ç»†ç²’åº¦çš„å®‰å…¨æ§åˆ¶æœºåˆ¶ï¼š

```python
class MCPSecurityManager:
    """MCPå®‰å…¨ç®¡ç†å™¨"""
    
    def __init__(self):
        self.user_permissions = {}
        self.tool_policies = {}
    
    def set_user_permissions(self, user_id: str, permissions: list):
        """è®¾ç½®ç”¨æˆ·æƒé™"""
        self.user_permissions[user_id] = permissions
    
    def set_tool_policy(self, tool_name: str, policy: dict):
        """è®¾ç½®å·¥å…·è®¿é—®ç­–ç•¥"""
        self.tool_policies[tool_name] = policy
    
    def check_tool_access(self, user_id: str, tool_name: str, arguments: dict) -> bool:
        """æ£€æŸ¥å·¥å…·è®¿é—®æƒé™"""
        user_perms = self.user_permissions.get(user_id, [])
        tool_policy = self.tool_policies.get(tool_name, {})
        
        # æ£€æŸ¥åŸºæœ¬æƒé™
        required_permission = tool_policy.get("required_permission")
        if required_permission and required_permission not in user_perms:
            return False
        
        # æ£€æŸ¥å‚æ•°é™åˆ¶
        param_restrictions = tool_policy.get("parameter_restrictions", {})
        for param, restriction in param_restrictions.items():
            if param in arguments:
                if not self.validate_parameter(arguments[param], restriction):
                    return False
        
        return True
    
    def validate_parameter(self, value, restriction):
        """éªŒè¯å‚æ•°å€¼"""
        if restriction["type"] == "whitelist":
            return value in restriction["allowed_values"]
        elif restriction["type"] == "pattern":
            import re
            return re.match(restriction["pattern"], str(value))
        
        return True

# ä½¿ç”¨å®‰å…¨ç®¡ç†å™¨
security_manager = MCPSecurityManager()

# é…ç½®æƒé™
security_manager.set_user_permissions("user_123", ["crm.read", "hr.read"])
security_manager.set_tool_policy("search_customer", {
    "required_permission": "crm.read",
    "parameter_restrictions": {
        "customer_id": {
            "type": "pattern",
            "pattern": r"^CUST-\d{6}$"
        }
    }
})
```


## ä¹ã€ReActæ™ºèƒ½ä½“ï¼šæ¨ç†ä¸è¡ŒåŠ¨çš„ç»“åˆ

ReActï¼ˆReasoning and Actingï¼‰æ˜¯ä¸€ç§å¼ºå¤§çš„æ™ºèƒ½ä½“è®¾è®¡æ¨¡å¼ï¼Œå®ƒå°†æ¨ç†ï¼ˆReasoningï¼‰å’Œè¡ŒåŠ¨ï¼ˆActingï¼‰ç»“åˆåœ¨ä¸€èµ·ï¼Œè®©AIèƒ½å¤Ÿåœ¨è§£å†³é—®é¢˜çš„è¿‡ç¨‹ä¸­äº¤æ›¿è¿›è¡Œæ€è€ƒå’Œæ‰§è¡Œã€‚LangGraphæä¾›äº†å†…ç½®çš„ReActæ™ºèƒ½ä½“å®ç°ï¼Œå¤§å¤§ç®€åŒ–äº†å¼€å‘è¿‡ç¨‹ã€‚

### 9.1 ReActæ¨¡å¼çš„æ ¸å¿ƒæ€æƒ³

ReActæ¨¡å¼çš„å·¥ä½œæµç¨‹æ˜¯ä¸€ä¸ªå¾ªç¯ï¼š

1. **è§‚å¯Ÿï¼ˆObservationï¼‰**ï¼šåˆ†æå½“å‰çŠ¶æ€å’Œç”¨æˆ·éœ€æ±‚
2. **æ€è€ƒï¼ˆThoughtï¼‰**ï¼šæ¨ç†ä¸‹ä¸€æ­¥åº”è¯¥åšä»€ä¹ˆ
3. **è¡ŒåŠ¨ï¼ˆActionï¼‰**ï¼šæ‰§è¡Œå…·ä½“çš„å·¥å…·è°ƒç”¨æˆ–æ“ä½œ
4. **è§‚å¯Ÿï¼ˆObservationï¼‰**ï¼šåˆ†æè¡ŒåŠ¨çš„ç»“æœ
5. **é‡å¤**ï¼šç›´åˆ°å®Œæˆä»»åŠ¡æˆ–è¾¾åˆ°åœæ­¢æ¡ä»¶

è¿™ç§æ¨¡å¼è®©æ™ºèƒ½ä½“èƒ½å¤Ÿåƒäººç±»ä¸€æ ·è¿›è¡Œæœ‰è®¡åˆ’çš„é—®é¢˜è§£å†³ã€‚

### 9.2 ä½¿ç”¨create_react_agentå¿«é€Ÿåˆ›å»ºæ™ºèƒ½ä½“

LangGraphæä¾›äº†`create_react_agent`å‡½æ•°ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿå¿«é€Ÿåˆ›å»ºReActæ™ºèƒ½ä½“ï¼š

```python
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from langchain_openai import ChatOpenAI

# å®šä¹‰å·¥å…·
@tool
def calculator(expression: str) -> str:
    """è®¡ç®—æ•°å­¦è¡¨è¾¾å¼
    
    Args:
        expression: è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ "2 + 3 * 4"
    
    Returns:
        è®¡ç®—ç»“æœ
    """
    try:
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"

@tool
def search_web(query: str) -> str:
    """æœç´¢ç½‘ç»œä¿¡æ¯
    
    Args:
        query: æœç´¢å…³é”®è¯
        
    Returns:
        æœç´¢ç»“æœæ‘˜è¦
    """
    # è¿™é‡Œåº”è¯¥è°ƒç”¨å®é™…çš„æœç´¢API
    return f"æœç´¢ '{query}' çš„ç»“æœ: [æ¨¡æ‹Ÿçš„æœç´¢ç»“æœ]"

@tool
def get_current_time() -> str:
    """è·å–å½“å‰æ—¶é—´
    
    Returns:
        å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´
    """
    from datetime import datetime
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# åˆ›å»ºReActæ™ºèƒ½ä½“
def create_business_assistant():
    """åˆ›å»ºå•†ä¸šåŠ©æ‰‹ReActæ™ºèƒ½ä½“"""
    
    # å®šä¹‰å¯ç”¨å·¥å…·
    tools = [calculator, search_web, get_current_time]
    
    # åˆ›å»ºæ¨¡å‹
    model = ChatOpenAI(
        model="gpt-4",
        temperature=0.1
    )
    
    # åˆ›å»ºReActæ™ºèƒ½ä½“
    agent = create_react_agent(
        model=model,
        tools=tools,
        state_modifier="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å•†ä¸šåŠ©æ‰‹ã€‚è¯·å¸®åŠ©ç”¨æˆ·è§£å†³å„ç§å•†ä¸šé—®é¢˜ï¼ŒåŒ…æ‹¬è®¡ç®—ã€ä¿¡æ¯æŸ¥è¯¢ç­‰ã€‚åœ¨ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·æ¸…æ¥šåœ°è§£é‡Šä½ çš„æ¨ç†è¿‡ç¨‹ã€‚"
    )
    
    return agent

# ä½¿ç”¨æ™ºèƒ½ä½“
business_agent = create_business_assistant()

# è¿è¡Œç¤ºä¾‹
config = {"configurable": {"thread_id": "business_session_1"}}
result = business_agent.invoke({
    "messages": [{"role": "user", "content": "è¯·å¸®æˆ‘è®¡ç®—ä¸€ä¸‹å¦‚æœæˆ‘æ¯æœˆæŠ•èµ„1000å…ƒï¼Œå¹´åŒ–æ”¶ç›Šç‡ä¸º8%ï¼Œ10å¹´åæ€»å…±èƒ½ç§¯ç´¯å¤šå°‘èµ„é‡‘ï¼Ÿ"}]
}, config)

print(result["messages"][-1].content)
```

### 9.3 è‡ªå®šä¹‰ReActæ™ºèƒ½ä½“çš„çŠ¶æ€

æœ‰æ—¶æˆ‘ä»¬éœ€è¦åœ¨ReActæ™ºèƒ½ä½“ä¸­ç»´æŠ¤é¢å¤–çš„çŠ¶æ€ä¿¡æ¯ï¼š

```python
from typing_extensions import TypedDict
from langgraph.prebuilt import create_react_agent

class CustomAgentState(TypedDict):
    """è‡ªå®šä¹‰æ™ºèƒ½ä½“çŠ¶æ€"""
    messages: list
    user_profile: dict
    conversation_context: dict
    task_progress: dict

def create_enhanced_react_agent():
    """åˆ›å»ºå¢å¼ºçš„ReActæ™ºèƒ½ä½“"""
    
    # å®šä¹‰å·¥å…·ï¼ˆåŒ…å«çŠ¶æ€è®¿é—®èƒ½åŠ›ï¼‰
    @tool
    def update_user_profile(user_info: str) -> str:
        """æ›´æ–°ç”¨æˆ·æ¡£æ¡ˆä¿¡æ¯
        
        Args:
            user_info: ç”¨æˆ·ä¿¡æ¯æè¿°
            
        Returns:
            æ›´æ–°çŠ¶æ€
        """
        # è¿™é‡Œå¯ä»¥è®¿é—®å’Œæ›´æ–°çŠ¶æ€
        return f"ç”¨æˆ·æ¡£æ¡ˆå·²æ›´æ–°: {user_info}"
    
    @tool
    def track_task_progress(task: str, status: str) -> str:
        """è·Ÿè¸ªä»»åŠ¡è¿›åº¦
        
        Args:
            task: ä»»åŠ¡åç§°
            status: ä»»åŠ¡çŠ¶æ€
            
        Returns:
            è¿›åº¦æ›´æ–°ç¡®è®¤
        """
        return f"ä»»åŠ¡ '{task}' çŠ¶æ€æ›´æ–°ä¸º: {status}"
    
    tools = [calculator, search_web, get_current_time, update_user_profile, track_task_progress]
    
    model = ChatOpenAI(model="gpt-4", temperature=0.1)
    
    # ä½¿ç”¨è‡ªå®šä¹‰çŠ¶æ€åˆ›å»ºæ™ºèƒ½ä½“
    agent = create_react_agent(
        model=model,
        tools=tools,
        state_schema=CustomAgentState,
        state_modifier="ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½çš„ä¸ªäººåŠ©æ‰‹ã€‚è¯·è®°ä½ç”¨æˆ·çš„åå¥½å’Œä»»åŠ¡è¿›åº¦ï¼Œæä¾›ä¸ªæ€§åŒ–çš„å¸®åŠ©ã€‚"
    )
    
    return agent
```

### 9.4 ReActæ™ºèƒ½ä½“çš„æç¤ºè¯ä¼˜åŒ–

æˆ‘ä»¬å¯ä»¥é€šè¿‡è‡ªå®šä¹‰æç¤ºè¯æ¥ä¼˜åŒ–ReActæ™ºèƒ½ä½“çš„è¡Œä¸ºï¼š

```python
def create_specialized_react_agent(domain: str):
    """åˆ›å»ºä¸“ä¸šé¢†åŸŸçš„ReActæ™ºèƒ½ä½“"""
    
    # æ ¹æ®é¢†åŸŸå®šåˆ¶æç¤ºè¯
    domain_prompts = {
        "finance": """
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡‘èåˆ†æå¸ˆåŠ©æ‰‹ã€‚åœ¨å¤„ç†é‡‘èç›¸å…³é—®é¢˜æ—¶ï¼š
        1. å§‹ç»ˆè€ƒè™‘é£é™©å› ç´ å’Œå¸‚åœºæ³¢åŠ¨æ€§
        2. æä¾›åŸºäºæ•°æ®çš„åˆ†æï¼Œé¿å…æŠ•èµ„å»ºè®®
        3. ä½¿ç”¨è®¡ç®—å™¨å·¥å…·è¿›è¡Œç²¾ç¡®çš„æ•°å€¼è®¡ç®—
        4. åœ¨éœ€è¦æœ€æ–°å¸‚åœºä¿¡æ¯æ—¶ä½¿ç”¨æœç´¢å·¥å…·
        """,
        
        "technical": """
        ä½ æ˜¯ä¸€ä½æŠ€æœ¯ä¸“å®¶åŠ©æ‰‹ã€‚åœ¨è§£å†³æŠ€æœ¯é—®é¢˜æ—¶ï¼š
        1. å…ˆç†è§£é—®é¢˜çš„æŠ€æœ¯èƒŒæ™¯å’Œè¦æ±‚
        2. åˆ†æ­¥éª¤åˆ†æé—®é¢˜å¹¶åˆ¶å®šè§£å†³æ–¹æ¡ˆ
        3. ä½¿ç”¨æœç´¢å·¥å…·è·å–æœ€æ–°çš„æŠ€æœ¯ä¿¡æ¯
        4. æä¾›è¯¦ç»†çš„æŠ€æœ¯è§£é‡Šå’Œå®æ–½æ­¥éª¤
        """,
        
        "general": """
        ä½ æ˜¯ä¸€ä½é€šç”¨æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·ï¼š
        1. ä»”ç»†åˆ†æç”¨æˆ·éœ€æ±‚
        2. é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥è·å–ä¿¡æ¯æˆ–æ‰§è¡Œä»»åŠ¡
        3. æä¾›æ¸…æ™°ã€æœ‰ç”¨çš„å›ç­”
        4. åœ¨ä¸ç¡®å®šæ—¶ä¸»åŠ¨å¯»æ±‚æ¾„æ¸…
        """
    }
    
    prompt = domain_prompts.get(domain, domain_prompts["general"])
    
    tools = [calculator, search_web, get_current_time]
    model = ChatOpenAI(model="gpt-4", temperature=0.1)
    
    agent = create_react_agent(
        model=model,
        tools=tools,
        state_modifier=prompt
    )
    
    return agent

# åˆ›å»ºé‡‘èåˆ†æåŠ©æ‰‹
finance_agent = create_specialized_react_agent("finance")

# åˆ›å»ºæŠ€æœ¯æ”¯æŒåŠ©æ‰‹  
tech_agent = create_specialized_react_agent("technical")
```

### 9.5 ReActæ™ºèƒ½ä½“çš„æ‰§è¡Œæ§åˆ¶

æˆ‘ä»¬å¯ä»¥å¯¹ReActæ™ºèƒ½ä½“çš„æ‰§è¡Œè¿‡ç¨‹è¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ï¼š

```python
def create_controlled_react_agent():
    """åˆ›å»ºå¯æ§åˆ¶çš„ReActæ™ºèƒ½ä½“"""
    
    tools = [calculator, search_web, get_current_time]
    model = ChatOpenAI(model="gpt-4", temperature=0.1)
    
    # åˆ›å»ºå¸¦æœ‰æ‰§è¡Œé™åˆ¶çš„æ™ºèƒ½ä½“
    agent = create_react_agent(
        model=model,
        tools=tools,
        state_modifier="ä½ æ˜¯ä¸€ä¸ªé«˜æ•ˆçš„åŠ©æ‰‹ï¼Œè¯·åœ¨æœ€å°‘çš„æ­¥éª¤å†…å®Œæˆä»»åŠ¡ã€‚",
        max_execution_time=60,  # æœ€å¤§æ‰§è¡Œæ—¶é—´ï¼ˆç§’ï¼‰
        max_iterations=10       # æœ€å¤§è¿­ä»£æ¬¡æ•°
    )
    
    return agent

def run_with_timeout(agent, inputs, config, timeout=30):
    """å¸¦è¶…æ—¶æ§åˆ¶çš„æ™ºèƒ½ä½“æ‰§è¡Œ"""
    import asyncio
    
    async def run_agent():
        return agent.invoke(inputs, config)
    
    try:
        # è®¾ç½®è¶…æ—¶
        result = asyncio.wait_for(run_agent(), timeout=timeout)
        return result
    except asyncio.TimeoutError:
        return {"error": "æ™ºèƒ½ä½“æ‰§è¡Œè¶…æ—¶"}
    except Exception as e:
        return {"error": f"æ‰§è¡Œé”™è¯¯: {str(e)}"}
```

### 9.6 ReActæ™ºèƒ½ä½“çš„æµå¼æ‰§è¡Œ

å¯¹äºéœ€è¦å®æ—¶åé¦ˆçš„åœºæ™¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æµå¼æ‰§è¡Œï¼š

```python
def stream_react_agent_execution():
    """æµå¼æ‰§è¡ŒReActæ™ºèƒ½ä½“"""
    
    agent = create_business_assistant()
    
    inputs = {
        "messages": [{"role": "user", "content": "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹å½“å‰çš„è‚¡å¸‚è¶‹åŠ¿ï¼Œå¹¶è®¡ç®—å¦‚æœæŠ•èµ„10ä¸‡å…ƒçš„é¢„æœŸæ”¶ç›Š"}]
    }
    
    config = {"configurable": {"thread_id": "stream_session"}}
    
    print("ğŸ¤– æ™ºèƒ½ä½“å¼€å§‹å·¥ä½œ...")
    
    # æµå¼æ‰§è¡Œï¼Œè§‚å¯Ÿæ¨ç†è¿‡ç¨‹
    for chunk in agent.stream(inputs, config, stream_mode="values"):
        messages = chunk.get("messages", [])
        if messages:
            last_message = messages[-1]
            
            # æ˜¾ç¤ºæ™ºèƒ½ä½“çš„æ€è€ƒè¿‡ç¨‹
            if last_message.type == "ai":
                if "æ€è€ƒ" in last_message.content or "Thought" in last_message.content:
                    print(f"ğŸ¤” æ€è€ƒ: {last_message.content}")
                elif "è¡ŒåŠ¨" in last_message.content or "Action" in last_message.content:
                    print(f"ğŸ”§ è¡ŒåŠ¨: {last_message.content}")
                else:
                    print(f"ğŸ’­ å›åº”: {last_message.content}")
            
            elif last_message.type == "tool":
                print(f"ğŸ› ï¸  å·¥å…·ç»“æœ: {last_message.content}")

# è¿è¡Œæµå¼æ‰§è¡Œç¤ºä¾‹
# stream_react_agent_execution()
```

### 9.7 ReActæ™ºèƒ½ä½“ä¸MCPé›†æˆ

ReActæ™ºèƒ½ä½“å¯ä»¥ä¸MCPå·¥å…·æ— ç¼é›†æˆï¼Œå®ç°çœŸæ­£çš„ä¼ä¸šçº§åº”ç”¨ï¼š

```python
from langgraph.prebuilt import create_react_agent

class MCPConnectionManager:
    """MCPè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self, sse_url: str):
        self.sse_url = sse_url
        self.client = None
        self.tools = []
    
    async def connect(self):
        """è¿æ¥åˆ°MCPæœåŠ¡å™¨"""
        try:
            # åˆ›å»ºMCPå®¢æˆ·ç«¯é…ç½®
            server_config = {
                "mcp_server": {
                    "transport": "sse",
                    "url": self.sse_url
                }
            }
            
            # è¿æ¥åˆ°MCPæœåŠ¡å™¨
            self.client = MultiServerMCPClient(server_config)
            self.tools = await self.client.get_tools()
            
            print("âœ… æˆåŠŸè¿æ¥åˆ°MCPæœåŠ¡å™¨")
            print(f"ğŸ› ï¸ å‘ç° {len(self.tools)} ä¸ªå¯ç”¨å·¥å…·")
            
            for tool in self.tools:
                print(f"  â€¢ {tool.name}: {tool.description}")
            
            return True
            
        except Exception as e:
            print(f"âŒ è¿æ¥MCPæœåŠ¡å™¨å¤±è´¥: {e}")
            raise Exception(f"MCPæœåŠ¡å™¨è¿æ¥å¤±è´¥: {e}") from e
    
    def get_tools(self):
        """è·å–MCPå·¥å…·åˆ—è¡¨"""
        return self.tools

async def create_react_agent_with_mcp(sse_url: str):
    """åˆ›å»ºé›†æˆçœŸå®MCPçš„ReAct Agent"""
    
    # è¿æ¥MCPæœåŠ¡å™¨
    mcp_manager = MCPConnectionManager(sse_url)
    await mcp_manager.connect()
    
    # è·å–MCPå·¥å…·
    mcp_tools = mcp_manager.get_tools()
    
    if not mcp_tools:
        print("âš ï¸ æ²¡æœ‰å¯ç”¨çš„MCPå·¥å…·")
        return None, None
    
    # åˆ›å»ºLLM
    llm = get_llm()
    
    # åˆ›å»ºç³»ç»Ÿæç¤º
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½è¿ç»´åŠ©æ‰‹ï¼Œå…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š

ğŸ¤– **æ ¸å¿ƒèƒ½åŠ›**:
- é€šè¿‡MCPå·¥å…·è¿œç¨‹æ‰§è¡Œç³»ç»Ÿå‘½ä»¤
- åˆ†æç³»ç»ŸçŠ¶æ€å’Œæ€§èƒ½æŒ‡æ ‡
- æä¾›è¿ç»´å»ºè®®å’Œè§£å†³æ–¹æ¡ˆ

ğŸ› ï¸ **å¯ç”¨å·¥å…·**:
- remote_exec: åœ¨è¿œç¨‹è®¾å¤‡ä¸Šæ‰§è¡Œshellå‘½ä»¤
  å‚æ•°: machineId (è®¾å¤‡ID), script (shellå‘½ä»¤)

ğŸ’¡ **å·¥ä½œæ–¹å¼**:
1. ä»”ç»†åˆ†æç”¨æˆ·éœ€æ±‚
2. åˆ¶å®šæ‰§è¡Œè®¡åˆ’
3. ä½¿ç”¨åˆé€‚çš„å·¥å…·è·å–ä¿¡æ¯
4. åˆ†æç»“æœå¹¶æä¾›ä¸“ä¸šå»ºè®®

è¯·æŒ‰ç…§ReActæ¨¡å¼å·¥ä½œï¼šè§‚å¯Ÿ â†’ æ€è€ƒ â†’ è¡ŒåŠ¨ â†’ è§‚å¯Ÿï¼Œç›´åˆ°å®Œæˆä»»åŠ¡ã€‚
"""
    
    # ä½¿ç”¨create_react_agentåˆ›å»ºReActä»£ç†
    react_agent = create_react_agent(
        llm,
        mcp_tools,
        state_modifier=system_prompt
    )
    
    print("âœ… ReAct Agentåˆ›å»ºæˆåŠŸ")
    
    return react_agent, mcp_manager

# æµ‹è¯•ç¤ºä¾‹
async def test_react_agent_with_mcp(sse_url: str = None):
    """æµ‹è¯•ReAct Agent + MCPé›†æˆ"""
    
    # ä½¿ç”¨é»˜è®¤URLæˆ–ç”¨æˆ·æä¾›çš„URL
    if not sse_url:
        sse_url = "http://localhost:8000/mcp/sse"  # é»˜è®¤URL
    
    print(f"ğŸŒ ä½¿ç”¨MCPæœåŠ¡å™¨: {sse_url}")
    
    try:
        # åˆ›å»ºReAct Agent
        agent, mcp_manager = await create_react_agent_with_mcp(sse_url)
        
        if not agent or not mcp_manager:
            print("âš ï¸ æ— æ³•åˆ›å»ºMCPé›†æˆçš„ReAct Agent")
            return
        
        # å®šä¹‰æµ‹è¯•åœºæ™¯
        test_scenarios = [
            {
                "name": "ç³»ç»Ÿå¥åº·æ£€æŸ¥",
                "query": "è¯·å¸®æˆ‘å…¨é¢æ£€æŸ¥è®¾å¤‡ 6fa31edaac8bee6cc75cd8ae1bc03930 çš„ç³»ç»Ÿå¥åº·çŠ¶å†µï¼ŒåŒ…æ‹¬CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨æƒ…å†µ"
            },
            {
                "name": "æ€§èƒ½åˆ†æ",
                "query": "è®¾å¤‡ 6fa31edaac8bee6cc75cd8ae1bc03930 è¿è¡Œç¼“æ…¢ï¼Œè¯·å¸®æˆ‘åˆ†æå¯èƒ½çš„åŸå› å¹¶æä¾›ä¼˜åŒ–å»ºè®®"
            },
            {
                "name": "æ•…éšœæ’æŸ¥",
                "query": "è®¾å¤‡ 6fa31edaac8bee6cc75cd8ae1bc03930 ä¸Šçš„æŸä¸ªæœåŠ¡å¯èƒ½æœ‰é—®é¢˜ï¼Œè¯·å¸®æˆ‘æ£€æŸ¥ç³»ç»Ÿæ—¥å¿—å’Œè¿è¡ŒçŠ¶æ€"
            }
        ]
        
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"ğŸ§ª æµ‹è¯•åœºæ™¯ {i}: {scenario['name']}")
            print(f"ğŸ“ ç”¨æˆ·è¯·æ±‚: {scenario['query']}")
            
            try:
                # è°ƒç”¨ReAct Agent
                result = await agent.ainvoke({
                    "messages": [{"role": "user", "content": scenario['query']}]
                })
                
                # è·å–æœ€ç»ˆå›å¤
                final_message = result["messages"][-1]
                
                if hasattr(final_message, 'content') and final_message.content:
                    # æ˜¾ç¤ºReActæ¨ç†è¿‡ç¨‹
                    print("\nğŸ§  ReActæ¨ç†è¿‡ç¨‹:")
                    thought_count = 0
                    action_count = 0
                    
                    for j, msg in enumerate(result["messages"]):
                        if hasattr(msg, 'content') and msg.content:
                            content = msg.content
                            if "Thought:" in content or "æ€è€ƒ" in content:
                                thought_count += 1
                                print(f"  ğŸ’­ æ€è€ƒ{thought_count}: {content[:100]}...")
                            elif "Action:" in content or "è¡ŒåŠ¨" in content:
                                action_count += 1
                                print(f"  âš¡ è¡ŒåŠ¨{action_count}: {content[:100]}...")
                            elif "Observation:" in content or "è§‚å¯Ÿ" in content:
                                print(f"  ğŸ‘ï¸ è§‚å¯Ÿ: {content[:100]}...")
                    
                    # æ˜¾ç¤ºæœ€ç»ˆç»“æœ
                    print(f"âœ… æœ€ç»ˆå›å¤: {final_message.content[:300]}...")
                else:
                    print(f"ğŸ“‹ Agentç»“æœ: {str(final_message)[:300]}...")
                    
            except Exception as e:
                print(f"âŒ æµ‹è¯•åœºæ™¯å¤±è´¥: {str(e)}")
            
            print("=" * 80)
        
        print("âœ… ReAct Agent + MCPé›†æˆæµ‹è¯•å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ MCPé›†æˆæµ‹è¯•å¤±è´¥: {e}")
```



ReActæ¨¡å¼çš„å¼ºå¤§ä¹‹å¤„åœ¨äºå®ƒæ¨¡æ‹Ÿäº†äººç±»è§£å†³é—®é¢˜çš„æ–¹å¼ï¼šæ€è€ƒ-è¡ŒåŠ¨-è§‚å¯Ÿ-å†æ€è€ƒã€‚é€šè¿‡ LangGraph çš„`create_react_agent`å’Œ MCP é›†æˆï¼Œæˆ‘ä»¬å¯ä»¥å¿«é€Ÿæ„å»ºå‡ºæ—¢èƒ½æ€è€ƒåˆèƒ½è¡ŒåŠ¨çš„ä¼ä¸šçº§æ™ºèƒ½ä½“ï¼Œå¤§å¤§æå‡äº† AI åº”ç”¨çš„å®ç”¨æ€§å’Œå¯é æ€§ã€‚


## æ€»ç»“ä¸å±•æœ›


é€šè¿‡æœ¬æ–‡çš„å­¦ä¹ ï¼Œä½ å·²ç»æŒæ¡äº†æ„å»ºä¼ä¸šçº§æ™ºèƒ½ä½“çš„æ ¸å¿ƒæŠ€èƒ½ã€‚ä»åŸºç¡€çš„å›¾å½¢APIåˆ°é«˜çº§çš„ReActæ™ºèƒ½ä½“ï¼Œä»ç®€å•çš„çŠ¶æ€ç®¡ç†åˆ°å¤æ‚çš„MCPé›†æˆï¼ŒLangGraphä¸ºæˆ‘ä»¬æä¾›äº†å®Œæ•´çš„è§£å†³æ–¹æ¡ˆã€‚

è®°ä½ï¼Œæœ€å¥½çš„æ™ºèƒ½ä½“ä¸æ˜¯é‚£ä¸ªèƒ½åšæ‰€æœ‰äº‹æƒ…çš„ï¼Œè€Œæ˜¯é‚£ä¸ªèƒ½åœ¨æ­£ç¡®çš„æ—¶é—´ã€ä»¥æ­£ç¡®çš„æ–¹å¼åšæ­£ç¡®äº‹æƒ…çš„ã€‚LangGraphç»™äº†æˆ‘ä»¬è¿™æ ·çš„èƒ½åŠ›ï¼Œç°åœ¨è½®åˆ°æˆ‘ä»¬å»åˆ›é€ çœŸæ­£æœ‰ä»·å€¼çš„AIåº”ç”¨äº†ã€‚

æŒæ¡LangGraphè¿™æ ·çš„å…ˆè¿›æ¡†æ¶ï¼Œå°†ä¸ºä½ åœ¨AIæ—¶ä»£çš„ç«äº‰ä¸­å å¾—å…ˆæœºã€‚è®©æˆ‘ä»¬ä¸€èµ·æ„å»ºæ›´æ™ºèƒ½ã€æ›´å¯é ã€æ›´æœ‰ä»·å€¼çš„ä¼ä¸šçº§AIåº”ç”¨ï¼

---

*ä¸‹ä¸€ç¯‡é¢„å‘Šï¼šã€Šä¼ä¸šçº§ Agent å¼€å‘å®æˆ˜(äºŒ) MCPåè®®è§£æåŠå®æˆ˜ MCPServerã€‹* 